{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/home/helfrech/Tools/Toolbox/utils')\n",
    "\n",
    "# Maths\n",
    "import numpy as np\n",
    "\n",
    "# ML\n",
    "from kernels import gaussian_kernel\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.preprocessing import KernelCenterer\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Utilities\n",
    "import h5py\n",
    "from tempfile import mkdtemp\n",
    "from shutil import rmtree\n",
    "from tqdm.notebook import tqdm\n",
    "from tools import load_json, save_json\n",
    "import project_utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: table generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SOAP cutoffs\n",
    "soap_hyperparameters = load_json('../Processed_Data/soap_hyperparameters.json')   \n",
    "cutoffs = soap_hyperparameters['interaction_cutoff']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Load train and test set indices for Deem\n",
    "deem_train_idxs = np.loadtxt('../Processed_Data/DEEM_330k/train.idxs', dtype=int)\n",
    "deem_test_idxs = np.loadtxt('../Processed_Data/DEEM_330k/test.idxs', dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN TMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train and test set indices for Deem\n",
    "# Train and test sets (random DEEM)\n",
    "from numpy.random import default_rng\n",
    "idxs_delete = np.loadtxt('../Processed_Data/DEEM_330k/10kJmol_error.idxs', dtype=int)\n",
    "deem_10k_idxs = np.loadtxt('../Processed_Data/DEEM_330k/deem_10k.idxs', dtype=int)\n",
    "\n",
    "n_total = 331172\n",
    "n_train = 10000\n",
    "n_test = 250\n",
    "rng = default_rng(seed=11011)\n",
    "idxs = np.arange(0, n_total)\n",
    "idxs = np.delete(idxs, idxs_delete)\n",
    "rng.shuffle(idxs)\n",
    "deem_train_idxs = idxs[0:n_train]\n",
    "deem_test_idxs = idxs[n_train:n_train + n_test]\n",
    "\n",
    "idxs_sort = np.argsort(deem_train_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# END TMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train and test set indices for IZA\n",
    "iza_train_idxs = np.loadtxt('../Processed_Data/IZA_226/train.idxs', dtype=int)\n",
    "iza_test_idxs = np.loadtxt('../Processed_Data/IZA_226/test.idxs', dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set property names for loading\n",
    "property_names = ['volumes', 'energies']\n",
    "\n",
    "# Load structure properties\n",
    "structure_properties = {}\n",
    "for pn in property_names:\n",
    "    structure_properties[pn] = np.loadtxt(f'../Processed_Data/DEEM_330k/Data/structure_{pn}.dat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = '../Processed_Data/Models'\n",
    "\n",
    "deem_name = 'DEEM_330k'\n",
    "iza_name = 'IZA_226'\n",
    "deem_dir = f'../Processed_Data/{deem_name}/Data'\n",
    "iza_dir = f'../Processed_Data/{iza_name}/Data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7bed8f3eef94f279bc5bd1f6822c683",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Cutoff', max=2.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Property', max=2.0, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Batch', max=4.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Batch', max=4.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Property', max=2.0, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Batch', max=4.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Batch', max=4.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Loop over cutoffs\n",
    "for cutoff in tqdm(cutoffs, desc='Cutoff', leave=True):\n",
    "    \n",
    "    # Set data directory\n",
    "    data_dir = f'../Processed_Data/DEEM_330k/Data/{cutoff}'\n",
    "    \n",
    "    # Read SOAPs in training set\n",
    "    deem_file = f'{deem_dir}/{cutoff}/soaps_power_full_avg_nonorm.hdf5'\n",
    "    f = h5py.File(deem_file, 'r')\n",
    "    deem_330k_dataset = f['0']\n",
    "    \n",
    "    #iza_file = f'{iza_dir}/{cutoff}/soaps_{spectrum_type}_full_avg_nonorm.hdf5'\n",
    "    #iza_soaps = utils.load_hdf5(iza_file)\n",
    "    \n",
    "    iza_soaps = utils.load_hdf5(f'{iza_dir}/{cutoff}/soaps_power_full_avg_nonorm.hdf5', datasets=None, concatenate=True)\n",
    "    \n",
    "    # Prepare batches for LR\n",
    "    n_samples_330k = deem_330k_dataset.len()\n",
    "    n_batches = n_samples_330k // batch_size\n",
    "    if n_samples_330k % batch_size > 0:\n",
    "        n_batches += 1\n",
    "    \n",
    "    # Loop over properties\n",
    "    for pn in tqdm(property_names, desc='Property', leave=False):\n",
    "        property_label = pn.capitalize()\n",
    "        \n",
    "        # Load the property values (just from the train set)\n",
    "        y = structure_properties[pn][deem_train_idxs[idxs_sort]] ###\n",
    "        \n",
    "        output_dir = f'Linear_Models/LR/{property_label}'\n",
    "        parameter_dir = f'{model_dir}/{cutoff}/{output_dir}'\n",
    "        os.makedirs(f'{deem_dir}/{cutoff}/{output_dir}', exist_ok=True)\n",
    "        os.makedirs(f'{iza_dir}/{cutoff}/{output_dir}', exist_ok=True)\n",
    "        \n",
    "        ridge_parameters = load_json(f'{parameter_dir}/ridge_parameters_mae.json')\n",
    "         \n",
    "        # Regression pipeline\n",
    "        cache_dir = mkdtemp()\n",
    "        pipeline = Pipeline(\n",
    "            [\n",
    "                ('norm_scaler', utils.NormScaler()), \n",
    "                ('ridge', TransformedTargetRegressor(\n",
    "                    regressor=Ridge(**ridge_parameters), \n",
    "                    transformer=utils.NormScaler()\n",
    "                ))\n",
    "            ],\n",
    "            memory=cache_dir\n",
    "        )\n",
    "        pipeline.fit(deem_330k_dataset[deem_train_idxs[idxs_sort]], y) ###\n",
    "        \n",
    "        iza_properties = pipeline.predict(iza_soaps)\n",
    "        \n",
    "        # Do DEEM 330k predictions in batches\n",
    "        deem_properties = np.zeros(n_samples_330k)\n",
    "        \n",
    "        for i in tqdm(range(0, n_batches), desc='Batch', leave=False):\n",
    "            batch_slice = slice(i * batch_size, (i + 1) * batch_size)\n",
    "            \n",
    "            deem_330k_batch = deem_330k_dataset[batch_slice]\n",
    "            deem_properties[batch_slice] = pipeline.predict(deem_330k_batch)\n",
    "        \n",
    "        np.savetxt(f'{deem_dir}/{cutoff}/{output_dir}/lr_structure_properties.dat', deem_properties)\n",
    "        np.savetxt(f'{iza_dir}/{cutoff}/{output_dir}/lr_structure_properties.dat', iza_properties)\n",
    "        \n",
    "        # Save the LR model and the scaler\n",
    "        save_json(pipeline.named_steps['norm_scaler'].__dict__, f'{parameter_dir}/norm_scaler.json', array_convert=True)\n",
    "        save_json(pipeline.named_steps['ridge'].regressor.__dict__, f'{parameter_dir}/ridge_regressor.json', array_convert=True)\n",
    "        save_json(pipeline.named_steps['ridge'].transformer.__dict__, f'{parameter_dir}/ridge_transformer.json', array_convert=True)\n",
    "        \n",
    "        rmtree(cache_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
