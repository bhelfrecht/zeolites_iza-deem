{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Maths\n",
    "import numpy as np\n",
    "\n",
    "# ML\n",
    "from kernels import gaussian_kernel\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.preprocessing import KernelCenterer\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Utilities\n",
    "import h5py\n",
    "from tempfile import mkdtemp\n",
    "from shutil import rmtree\n",
    "from tqdm.auto import tqdm\n",
    "from tools import load_json, save_json\n",
    "import project_utils as utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SOAP cutoffs\n",
    "soap_hyperparameters = load_json('../Processed_Data/soap_hyperparameters.json')   \n",
    "cutoffs = soap_hyperparameters['interaction_cutoff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = '../Processed_Data/Models'\n",
    "\n",
    "deem_name = 'DEEM_330k'\n",
    "iza_name = 'IZA_230'\n",
    "deem_dir = f'../Processed_Data/{deem_name}/Data'\n",
    "iza_dir = f'../Processed_Data/{iza_name}/Data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear ridge regression of molar volumes and energies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train and test set indices for Deem\n",
    "deem_train_idxs = np.loadtxt('../Processed_Data/DEEM_330k/ridge_train.idxs', dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set property names for loading\n",
    "property_names = ['volumes', 'energies']\n",
    "\n",
    "# Load structure properties\n",
    "structure_properties = {}\n",
    "for pn in property_names:\n",
    "    structure_properties[pn] = np.loadtxt(f'../Processed_Data/DEEM_330k/Data/structure_{pn}.dat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deem 10k train set (from ZAP1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ef4d3f4e91b4a19a0c6742321ba5785",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Cutoff', max=2.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Property', max=2.0, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Batch', max=4.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Batch', max=4.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Property', max=2.0, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Batch', max=4.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Batch', max=4.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Loop over cutoffs\n",
    "for cutoff in tqdm(cutoffs, desc='Cutoff', leave=True):\n",
    "    \n",
    "    # Set data directory\n",
    "    data_dir = f'../Processed_Data/DEEM_330k/Data/{cutoff}'\n",
    "    \n",
    "    # Read SOAPs in training set\n",
    "    deem_file = f'{deem_dir}/{cutoff}/soaps_power_full_avg_nonorm.hdf5'\n",
    "    f = h5py.File(deem_file, 'r')\n",
    "    deem_330k_dataset = f['0']\n",
    "    \n",
    "    iza_file = f'{iza_dir}/{cutoff}/soaps_power_full_avg_nonorm.hdf5'\n",
    "    iza_soaps = utils.load_hdf5(iza_file)\n",
    "        \n",
    "    # Prepare batches for LR\n",
    "    n_samples_330k = deem_330k_dataset.len()\n",
    "    n_batches = n_samples_330k // batch_size\n",
    "    if n_samples_330k % batch_size > 0:\n",
    "        n_batches += 1\n",
    "    \n",
    "    # Loop over properties\n",
    "    for pn in tqdm(property_names, desc='Property', leave=False):\n",
    "        property_label = pn.capitalize()\n",
    "        \n",
    "        # Load the property values (just from the train set)\n",
    "        y = structure_properties[pn][deem_train_idxs]\n",
    "        \n",
    "        output_dir = f'LRR/{property_label}'\n",
    "        parameter_dir = f'{model_dir}/{cutoff}/{output_dir}'\n",
    "        os.makedirs(f'{deem_dir}/{cutoff}/{output_dir}', exist_ok=True)\n",
    "        os.makedirs(f'{iza_dir}/{cutoff}/{output_dir}', exist_ok=True)\n",
    "        \n",
    "        ridge_parameters = load_json(f'{parameter_dir}/ridge_parameters_mae.json')\n",
    "         \n",
    "        # Regression pipeline\n",
    "        pipeline = Pipeline(\n",
    "            [\n",
    "                ('norm_scaler', utils.StandardNormScaler()), \n",
    "                ('ridge', TransformedTargetRegressor(\n",
    "                    regressor=Ridge(**ridge_parameters), \n",
    "                    transformer=utils.StandardNormScaler()\n",
    "                ))\n",
    "            ],\n",
    "        )\n",
    "        pipeline.fit(deem_330k_dataset[deem_train_idxs], y)\n",
    "        \n",
    "        iza_properties = pipeline.predict(iza_soaps)\n",
    "        \n",
    "        # Do DEEM 330k predictions in batches\n",
    "        deem_properties = np.zeros(n_samples_330k)\n",
    "        \n",
    "        for i in tqdm(range(0, n_batches), desc='Batch', leave=False):\n",
    "            batch_slice = slice(i * batch_size, (i + 1) * batch_size)\n",
    "            \n",
    "            deem_330k_batch = deem_330k_dataset[batch_slice]\n",
    "            deem_properties[batch_slice] = pipeline.predict(deem_330k_batch)\n",
    "                \n",
    "        np.savetxt(f'{deem_dir}/{cutoff}/{output_dir}/lr_structure_properties.dat', deem_properties)\n",
    "        np.savetxt(f'{iza_dir}/{cutoff}/{output_dir}/lr_structure_properties.dat', iza_properties)\n",
    "        \n",
    "        # Save the LR model and the scaler\n",
    "        save_json(pipeline.named_steps['norm_scaler'].__dict__, f'{parameter_dir}/norm_scaler.json', array_convert=True)\n",
    "        save_json(pipeline.named_steps['ridge'].regressor_.__dict__, f'{parameter_dir}/ridge_regressor.json', array_convert=True)\n",
    "        save_json(pipeline.named_steps['ridge'].transformer_.__dict__, f'{parameter_dir}/ridge_transformer.json', array_convert=True)\n",
    "                \n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "deem_train_idxs_random = np.loadtxt('../Processed_Data/DEEM_330k/ridge_train_random.idxs', dtype=int)\n",
    "sort_idxs = np.argsort(deem_train_idxs_random)\n",
    "rev_idxs = np.argsort(sort_idxs)\n",
    "deem_train_idxs_random = deem_train_idxs_random[sort_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "503c70b2bf224ae784345497a3d787d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Cutoff', max=2.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Property', max=2.0, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Batch', max=4.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Batch', max=4.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Property', max=2.0, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Batch', max=4.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Batch', max=4.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Loop over cutoffs\n",
    "for cutoff in tqdm(cutoffs, desc='Cutoff', leave=True):\n",
    "    \n",
    "    # Set data directory\n",
    "    data_dir = f'../Processed_Data/DEEM_330k/Data/{cutoff}'\n",
    "    \n",
    "    # Read SOAPs in training set\n",
    "    deem_file = f'{deem_dir}/{cutoff}/soaps_power_full_avg_nonorm.hdf5'\n",
    "    f = h5py.File(deem_file, 'r')\n",
    "    deem_330k_dataset = f['0']\n",
    "    \n",
    "    iza_file = f'{iza_dir}/{cutoff}/soaps_power_full_avg_nonorm.hdf5'\n",
    "    iza_soaps = utils.load_hdf5(iza_file)\n",
    "        \n",
    "    # Prepare batches for LR\n",
    "    n_samples_330k = deem_330k_dataset.len()\n",
    "    n_batches = n_samples_330k // batch_size\n",
    "    if n_samples_330k % batch_size > 0:\n",
    "        n_batches += 1\n",
    "    \n",
    "    # Loop over properties\n",
    "    for pn in tqdm(property_names, desc='Property', leave=False):\n",
    "        property_label = pn.capitalize()\n",
    "        \n",
    "        # Load the property values (just from the train set)\n",
    "        y = structure_properties[pn][deem_train_idxs_random]\n",
    "        \n",
    "        output_dir = f'LRR/{property_label}'\n",
    "        parameter_dir = f'{model_dir}/{cutoff}/{output_dir}'\n",
    "        os.makedirs(f'{deem_dir}/{cutoff}/{output_dir}', exist_ok=True)\n",
    "        os.makedirs(f'{iza_dir}/{cutoff}/{output_dir}', exist_ok=True)\n",
    "        \n",
    "        ridge_parameters = load_json(f'{parameter_dir}/ridge_parameters_mae_random.json')\n",
    "         \n",
    "        # Regression pipeline\n",
    "        pipeline = Pipeline(\n",
    "            [\n",
    "                ('norm_scaler', utils.StandardNormScaler()), \n",
    "                ('ridge', TransformedTargetRegressor(\n",
    "                    regressor=Ridge(**ridge_parameters), \n",
    "                    transformer=utils.StandardNormScaler()\n",
    "                ))\n",
    "            ],\n",
    "        )\n",
    "        pipeline.fit(deem_330k_dataset[deem_train_idxs_random], y)\n",
    "        \n",
    "        iza_properties = pipeline.predict(iza_soaps)\n",
    "        \n",
    "        # Do DEEM 330k predictions in batches\n",
    "        deem_properties = np.zeros(n_samples_330k)\n",
    "        \n",
    "        for i in tqdm(range(0, n_batches), desc='Batch', leave=False):\n",
    "            batch_slice = slice(i * batch_size, (i + 1) * batch_size)\n",
    "            \n",
    "            deem_330k_batch = deem_330k_dataset[batch_slice]\n",
    "            deem_properties[batch_slice] = pipeline.predict(deem_330k_batch)\n",
    "                \n",
    "        np.savetxt(f'{deem_dir}/{cutoff}/{output_dir}/lr_structure_properties_random.dat', deem_properties)\n",
    "        np.savetxt(f'{iza_dir}/{cutoff}/{output_dir}/lr_structure_properties_random.dat', iza_properties)\n",
    "        \n",
    "        # Save the LR model and the scaler\n",
    "        save_json(pipeline.named_steps['norm_scaler'].__dict__, f'{parameter_dir}/norm_scaler_random.json', array_convert=True)\n",
    "        save_json(pipeline.named_steps['ridge'].regressor_.__dict__, f'{parameter_dir}/ridge_regressor_random.json', array_convert=True)\n",
    "        save_json(pipeline.named_steps['ridge'].transformer_.__dict__, f'{parameter_dir}/ridge_transformer_random.json', array_convert=True)\n",
    "                \n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear ridge regression of IZA compositions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cantons\n",
    "iza_cantons = np.loadtxt('../Raw_Data/IZA_230/cantons_compositions.dat', usecols=1, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "iza_train_idxs_composition = np.loadtxt('../Processed_Data/IZA_230/svm_train.idxs', dtype=int)\n",
    "# iza_train_idxs_composition = iza_train_idxs_composition[iza_cantons[iza_train_idxs_composition] != 3]\n",
    "\n",
    "iza_sort_idxs = np.argsort(iza_train_idxs_composition)\n",
    "iza_rev_idxs = np.argsort(iza_sort_idxs)\n",
    "iza_train_idxs_composition = iza_train_idxs_composition[iza_sort_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load compositions\n",
    "iza_compositions = np.loadtxt('../Raw_Data/IZA_230/cantons_compositions.dat', usecols=2)\n",
    "property_name = 'composition'\n",
    "property_label = property_name.capitalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfa7a69ba78b465f873db36f76664018",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Cutoff', max=2.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Batch', max=4.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Batch', max=4.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Loop over cutoffs\n",
    "for cutoff in tqdm(cutoffs, desc='Cutoff', leave=True):\n",
    "    \n",
    "    # Set data directory\n",
    "    data_dir = f'../Processed_Data/IZA_230/Data/{cutoff}'\n",
    "    \n",
    "    # Read SOAPs in training set\n",
    "    iza_file = f'{iza_dir}/{cutoff}/soaps_power_full_avg_nonorm.hdf5'\n",
    "    iza_soaps = utils.load_hdf5(iza_file)\n",
    "    \n",
    "    deem_file = f'{deem_dir}/{cutoff}/soaps_power_full_avg_nonorm.hdf5'\n",
    "    f = h5py.File(deem_file, 'r')\n",
    "    deem_330k_dataset = f['0']\n",
    "    \n",
    "    # Prepare batches for LR\n",
    "    n_samples_330k = deem_330k_dataset.len()\n",
    "    n_batches = n_samples_330k // batch_size\n",
    "    if n_samples_330k % batch_size > 0:\n",
    "        n_batches += 1\n",
    "    \n",
    "    output_dir = f'LRR/{property_label}'\n",
    "    parameter_dir = f'{model_dir}/{cutoff}/{output_dir}'\n",
    "    os.makedirs(f'{iza_dir}/{cutoff}/{output_dir}', exist_ok=True)\n",
    "    os.makedirs(f'{deem_dir}/{cutoff}/{output_dir}', exist_ok=True)\n",
    "\n",
    "    ridge_parameters = load_json(f'{parameter_dir}/ridge_parameters_mae.json')\n",
    "\n",
    "    # Regression pipeline\n",
    "    pipeline = Pipeline(\n",
    "        [\n",
    "            ('norm_scaler', utils.StandardNormScaler()), \n",
    "            ('ridge', TransformedTargetRegressor(\n",
    "                regressor=Ridge(**ridge_parameters), \n",
    "                transformer=utils.StandardNormScaler()\n",
    "            ))\n",
    "        ],\n",
    "    )\n",
    "    pipeline.fit(\n",
    "        iza_soaps[iza_train_idxs_composition],\n",
    "        iza_compositions[iza_train_idxs_composition]\n",
    "    )\n",
    "\n",
    "    predicted_iza_compositions = pipeline.predict(iza_soaps)\n",
    "    \n",
    "    # Do DEEM 330k predictions in batches\n",
    "    predicted_deem_compositions = np.zeros(n_samples_330k)\n",
    "\n",
    "    for i in tqdm(range(0, n_batches), desc='Batch', leave=False):\n",
    "        batch_slice = slice(i * batch_size, (i + 1) * batch_size)\n",
    "\n",
    "        deem_330k_batch = deem_330k_dataset[batch_slice]\n",
    "        predicted_deem_compositions[batch_slice] = pipeline.predict(deem_330k_batch)\n",
    "    \n",
    "    np.savetxt(f'{iza_dir}/{cutoff}/{output_dir}/lr_structure_properties.dat', predicted_iza_compositions)\n",
    "    np.savetxt(f'{deem_dir}/{cutoff}/{output_dir}/lr_structure_properties.dat', predicted_deem_compositions)\n",
    "    \n",
    "    # Save the LR model and the scaler\n",
    "    save_json(pipeline.named_steps['norm_scaler'].__dict__, f'{parameter_dir}/norm_scaler.json', array_convert=True)\n",
    "    save_json(pipeline.named_steps['ridge'].regressor_.__dict__, f'{parameter_dir}/ridge_regressor.json', array_convert=True)\n",
    "    save_json(pipeline.named_steps['ridge'].transformer_.__dict__, f'{parameter_dir}/ridge_transformer.json', array_convert=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
