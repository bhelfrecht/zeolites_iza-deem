{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/home/helfrech/Tools/Toolbox/utils')\n",
    "\n",
    "# Maths\n",
    "import numpy as np\n",
    "\n",
    "# ML\n",
    "from regression import SparseKRR\n",
    "from kernels import build_kernel\n",
    "from errors import MAE, RMSE\n",
    "\n",
    "# Utilities\n",
    "import h5py\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "from project_utils import load_structures_from_hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: table generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train and test sets\n",
    "train_idxs = np.loadtxt('../Processed_Data/DEEM_10k/train.idxs', dtype=int)\n",
    "test_idxs = np.loadtxt('../Processed_Data/DEEM_10k/test.idxs', dtype=int)\n",
    "\n",
    "# Total number of structures\n",
    "n_structures = train_idxs.size + test_idxs.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set structure labels for loading from the HDF5 file\n",
    "n_digits = len(str(n_structures - 1))\n",
    "datasets = [str(i).zfill(n_digits) for i in train_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SOAP cutoffs\n",
    "with open('../Processed_Data/soap_hyperparameters.json', 'r') as f:\n",
    "    soap_hyperparameters = json.load(f)\n",
    "    \n",
    "cutoffs = soap_hyperparameters['interaction_cutoff']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "representative_soaps = {}\n",
    "\n",
    "for cutoff in cutoffs:\n",
    "    work_dir = '../Processed_Data/DEEM_10k/Data/{cutoff}'\n",
    "    n_Si = np.loadtxt('{work_dir}/n_Si.dat', dtype=int)\n",
    "    split_idxs = np.cumsum(n_Si)[0:-1]\n",
    "    representative_idxs = np.loadtxt('{work_dir}/FPS_representatives.idxs', dtype=int)\n",
    "    soaps_file = '{work_dir}/soaps.hdf5'\n",
    "    representative_soaps['{cutoff}'] = build_representatives_from_hdf5(soaps_file, representative_idxs, split_idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_skrr_oos(cutoff, datasets, property_name,\n",
    "                   soaps_file, ref_soaps_file,\n",
    "                   rep_idxs_file, model_file,\n",
    "                   skrr_file, work_dir='.'):\n",
    "    \n",
    "    # Read SOAPs\n",
    "    soaps = load_structures_from_hdf5(soaps_file, datasets=None, concatenate=False)\n",
    "    \n",
    "    # Load reference SOAPs\n",
    "    representative_soaps = load_structures_from_hdf5(ref_soaps_file, datasets=datasets, concatenate=True)\n",
    "    representative_idxs = np.loadtxt(rep_idxs_file, usecols=0, dtype=int)\n",
    "    representative_soaps = representative_soaps[representative_idxs, :]\n",
    "    \n",
    "    # Unpickle the kernel parameters\n",
    "    with open(model_file, 'r') as f:\n",
    "        model_dict = json.load(f)\n",
    "        \n",
    "    kernel_type = model_dict['kernel_type']\n",
    "    gamma = model_dict['gamma']\n",
    "    \n",
    "    # Unpickle the reference models\n",
    "    with open(skrr_file, 'r') as f:\n",
    "        skrr_dict = json.load(f)\n",
    "                \n",
    "    # Turn lists into arrays\n",
    "    for k, v in skrr_dict.items():\n",
    "        if isinstance(v, list):\n",
    "            skrr_dict[k] = np.array(v)\n",
    "                        \n",
    "    # Build structure kernel\n",
    "    KNM = build_kernel(soaps, representative_soaps,\n",
    "                       kernel=kernel_type, gamma=gamma)\n",
    "        \n",
    "    # Initialize SKRR model\n",
    "    skrr = SparseKRR()\n",
    "    skrr.__dict__ = skrr_dict\n",
    "    \n",
    "    # Predict based on the loaded SparseKRR object\n",
    "    Yp_structures = skrr.transform(KNM)\n",
    "    \n",
    "    # Iteratively operate on environments to save memory\n",
    "    Yp_environments = []\n",
    "    for soap in tqdm(soaps):\n",
    "        KNM_environments = build_kernel(soap, representative_soaps,\n",
    "                                    kernel=kernel_type, gamma=gamma)\n",
    "        Yp_environments.append(skrr.transform(KNM_environments))\n",
    "        \n",
    "    Yp_environments = np.concatenate(Yp_environments)\n",
    "\n",
    "    np.savetxt(f'{work_dir}/predicted_structure_{property_name}.dat', Yp_structures)\n",
    "    np.savetxt(f'{work_dir}/predicted_environment_{property_name}.dat', Yp_environments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEEM_10k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set property names for loading\n",
    "property_names = ['volumes', 'energies']\n",
    "\n",
    "# Load structure properties\n",
    "structure_properties = {}\n",
    "for pn in property_names:\n",
    "    structure_properties[pn] = np.loadtxt(f'../Processed_Data/DEEM_10k/Data/structure_{pn}.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db1dcdad60224b25a5d59fda5b8ea923",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86d35f72a00d4f21b1b7c9d3b80d3c70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "254b50c87ec8457d9e15335cdb86cf18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6a5e95e8ae94b78bf5914777b081a81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for cutoff in cutoffs:\n",
    "    \n",
    "    # Set data directory\n",
    "    data_dir = f'../Processed_Data/Models/{cutoff}'\n",
    "    \n",
    "    # Set working directory\n",
    "    work_dir = f'../Processed_Data/DEEM_10k/Data/{cutoff}'\n",
    "    if not os.path.exists(work_dir):\n",
    "        os.mkdir(work_dir)\n",
    "    \n",
    "    # Set SOAP files\n",
    "    soaps_file = f'{work_dir}/soaps.hdf5'\n",
    "    rep_idxs_file = f'{work_dir}/FPS_representatives.idxs'\n",
    "            \n",
    "    # Read SOAPs\n",
    "    soaps = load_structures_from_hdf5(soaps_file, datasets=None, concatenate=False)\n",
    "    \n",
    "    # Build representative SOAPs\n",
    "    representative_idxs = np.loadtxt(rep_idxs_file, usecols=0, dtype=int)\n",
    "    representative_soaps = np.vstack([soaps[i] for i in train_idxs])\n",
    "    representative_soaps = representative_soaps[representative_idxs, :]\n",
    "    \n",
    "    # Loop over structure properties\n",
    "    for pn, Y in structure_properties.items():\n",
    "        \n",
    "        # Load model parameters\n",
    "        model_file = f'{data_dir}/{pn}_mae_parameters.json'\n",
    "\n",
    "        # Load kernel parameters\n",
    "        with open(model_file, 'r') as f:\n",
    "            model_dict = json.load(f)\n",
    "\n",
    "        kernel_type = model_dict['kernel_type']\n",
    "        gamma = model_dict['gamma']\n",
    "\n",
    "        # Build kernels\n",
    "        KMM = build_kernel(representative_soaps, representative_soaps,\n",
    "                           kernel=kernel_type, gamma=gamma)\n",
    "        KNM = build_kernel(soaps, representative_soaps,\n",
    "                           kernel=kernel_type, gamma=gamma)\n",
    "    \n",
    "        # Prepare properties and scaling\n",
    "        Yc = Y - np.mean(Y[train_idxs])\n",
    "        delta = np.var(Yc[train_idxs]) * KMM.shape[0] / np.trace(KMM)\n",
    "        \n",
    "        # Load regression parameters\n",
    "        sigma = model_dict['sigma']\n",
    "        reg = model_dict['reg']\n",
    "    \n",
    "        # Initialize sparse KRR\n",
    "        skrr = SparseKRR(sigma=sigma, reg=reg, rcond=None)\n",
    "        skrr.fit(delta*KNM[train_idxs, :], delta*KMM, delta*Yc[train_idxs])\n",
    "        \n",
    "        # Pickle the models\n",
    "        # Copy the dict so we can make the numpy arrays lists\n",
    "        skrr_dict = skrr.__dict__.copy()\n",
    "        \n",
    "        # Convert arrays to lists\n",
    "        for k, v in skrr_dict.items():\n",
    "            if isinstance(v, np.ndarray):\n",
    "                skrr_dict[k] = v.tolist()\n",
    "        \n",
    "        # Save\n",
    "        with open(f'{data_dir}/skrr_{pn}.json', 'w') as f:\n",
    "            json.dump(skrr_dict, f)\n",
    "        \n",
    "        # Predict properties\n",
    "        Yp_structures = np.zeros(len(soaps))\n",
    "        Yp_structures[train_idxs] = skrr.transform(KNM[train_idxs, :])\n",
    "        Yp_structures[test_idxs] = skrr.transform(KNM[test_idxs, :])\n",
    "        \n",
    "        # Iteratively predict environment properties to save memory\n",
    "        Yp_environments = []\n",
    "        for soap in tqdm(soaps):\n",
    "            KNM_environments = build_kernel(soap, representative_soaps,\n",
    "                                        kernel=kernel_type, gamma=gamma)\n",
    "            Yp_environments.append(skrr.transform(KNM_environments))\n",
    "\n",
    "        Yp_environments = np.concatenate(Yp_environments)\n",
    "        \n",
    "        # Save predicted properties\n",
    "        np.savetxt(f'{work_dir}/predicted_structure_{pn}.dat', Yp_structures)\n",
    "        np.savetxt(f'{work_dir}/predicted_environment_{pn}.dat', Yp_environments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IZA_226 on DEEM_10k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b10877bc6724a8d97ec76ecfb7a100c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=226.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7e3424ae9b54d0baff9c6f409aaada8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=226.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "170ec750213b46aebc4f2aa83dd72112",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=226.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceac8ab947964e81899d923eca2fe008",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=226.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for cutoff in cutoffs:\n",
    "    \n",
    "    # Set the working directory\n",
    "    work_dir = f'../Processed_Data/IZA_226onDEEM_10k/Data/{cutoff}'\n",
    "    if not os.path.exists(work_dir):\n",
    "        os.mkdir(work_dir)\n",
    "      \n",
    "    # Set the SOAP files\n",
    "    soaps_file = f'../Processed_Data/IZA_226onDEEM_10k/Data/{cutoff}/soaps.hdf5'\n",
    "    ref_soaps_file = f'../Processed_Data/DEEM_10k/Data/{cutoff}/soaps.hdf5'\n",
    "    rep_idxs_file = f'../Processed_Data/DEEM_10k/Data/{cutoff}/FPS_representatives.idxs'\n",
    "\n",
    "    # Compute SKRR predictions for each property\n",
    "    for pn in structure_properties.keys():\n",
    "        model_file = f'../Processed_Data/Models/{cutoff}/{pn}_mae_parameters.json'\n",
    "        skrr_file = f'../Processed_Data/Models/{cutoff}/skrr_{pn}.json'\n",
    "        transform_skrr_oos(cutoff, datasets, pn,\n",
    "                           soaps_file, ref_soaps_file,\n",
    "                           rep_idxs_file, model_file,\n",
    "                           skrr_file, work_dir=work_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COD_196 on DEEM_10k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "663defddaa314c9c8438a2840af6bf89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=196.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26c029bd77a844e6bc1048ca817e28c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=196.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0809e5b1894d4c9e9109d3629e14a5b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=196.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad57415ee2824f85bea5f2be1e2c8964",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=196.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for cutoff in cutoffs:\n",
    "    \n",
    "    # Set the working directory\n",
    "    work_dir = f'../Processed_Data/COD_196onDEEM_10k/Data/{cutoff}'\n",
    "    if not os.path.exists(work_dir):\n",
    "        os.mkdir(work_dir)\n",
    "      \n",
    "    # Set the SOAP files\n",
    "    soaps_file = f'../Processed_Data/COD_196onDEEM_10k/Data/{cutoff}/soaps.hdf5'\n",
    "    ref_soaps_file = f'../Processed_Data/DEEM_10k/Data/{cutoff}/soaps.hdf5'\n",
    "    rep_idxs_file = f'../Processed_Data/DEEM_10k/Data/{cutoff}/FPS_representatives.idxs'\n",
    "\n",
    "    # Compute SKRR predictions for each property\n",
    "    for pn in structure_properties.keys():\n",
    "        model_file = f'../Processed_Data/Models/{cutoff}/{pn}_mae_parameters.json'\n",
    "        skrr_file = f'../Processed_Data/Models/{cutoff}/skrr_{pn}.json'\n",
    "        transform_skrr_oos(cutoff, datasets, pn,\n",
    "                           soaps_file, ref_soaps_file,\n",
    "                           rep_idxs_file, model_file,\n",
    "                           skrr_file, work_dir=work_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_mean = {}\n",
    "for pn in ['volumes', 'energies']:\n",
    "    Y_mean[pn] = np.loadtxt(f'../Processed_Data/DEEM_10k/structure_{pn}.dat')\n",
    "    Y_mean[pn] = np.mean(Y_mean[pn][train_idxs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEEM_10k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5 volumes MAE: 2.5997947727897315\n",
      "3.5 volumes RMSE: 3.7752991352703043\n",
      "3.5 energies MAE: 0.6679147247205498\n",
      "3.5 energies RMSE: 0.9387783017460885\n",
      "6.0 volumes MAE: 1.0495045073138882\n",
      "6.0 volumes RMSE: 1.8395137747385406\n",
      "6.0 energies MAE: 0.4620307674679215\n",
      "6.0 energies RMSE: 0.6693558441871916\n"
     ]
    }
   ],
   "source": [
    "for cutoff in cutoffs:\n",
    "    for pn in ['volumes', 'energies']:\n",
    "        Y = np.loadtxt(f'../Processed_Data/DEEM_10k/structure_{pn}.dat')\n",
    "        Yp = np.loadtxt(f'../Processed_Data/DEEM_10k/Data/{cutoff}/predicted_structure_{pn}.dat')\n",
    "        Yp += Y_mean[pn]\n",
    "        mae = MAE(Y[test_idxs], Yp[test_idxs])\n",
    "        rmse = RMSE(Y[test_idxs], Yp[test_idxs])\n",
    "        \n",
    "        print(f'{cutoff} {pn} MAE: {mae}')\n",
    "        print(f'{cutoff} {pn} RMSE: {rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IZA_226 on DEEM_10k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "cantons = np.loadtxt('../Raw_Data/GULP/IZA_226/cantons.txt', usecols=1, dtype=int)\n",
    "canton_labels = np.unique(cantons)\n",
    "print(canton_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5 volumes MAE: 5.597071553718962 | [5.020883636526268, 5.133356486889813, 5.723347282333311, 73.75013726284374]\n",
      "3.5 volumes RMSE: 8.605924587042685 | [6.134566648951043, 6.918039863286284, 7.805476815109476, 73.75013726284374]\n",
      "3.5 energies MAE: 1.2295647615576781 | [1.373044032164554, 1.0360946547118863, 1.2324221456353692, 19.61684120822065]\n",
      "3.5 energies RMSE: 2.171330635572147 | [1.9481079899780755, 1.5760536561678975, 1.897466617273481, 19.61684120822065]\n",
      "6.0 volumes MAE: 2.1119540047946535 | [1.0388339319867168, 1.880866454355247, 2.306643039039767, 54.62498337801229]\n",
      "6.0 volumes RMSE: 4.900791784046571 | [1.2504230461314574, 3.339528549606324, 3.889657173836812, 54.62498337801229]\n",
      "6.0 energies MAE: 0.612571796556233 | [0.7003589840531017, 0.5632240906939902, 0.5117597908439594, 10.415656737794052]\n",
      "6.0 energies RMSE: 1.057806574792901 | [1.1468966982608606, 0.7223079787003455, 0.7144406626110872, 10.415656737794052]\n"
     ]
    }
   ],
   "source": [
    "for cutoff in cutoffs:\n",
    "    for pn in ['volumes', 'energies']:\n",
    "        Y = np.loadtxt(f'../Processed_Data/IZA_226/structure_{pn}.dat')\n",
    "        Yp = np.loadtxt(f'../Processed_Data/IZA_226onDEEM_10k/Data/{cutoff}/predicted_structure_{pn}.dat')\n",
    "        Yp += Y_mean[pn]\n",
    "        mae = MAE(Y, Yp)\n",
    "        rmse = RMSE(Y, Yp)\n",
    "        \n",
    "        mae_cantons = []\n",
    "        rmse_cantons = []\n",
    "        for canton in canton_labels:\n",
    "            canton_idxs = np.nonzero(cantons == canton)[0]\n",
    "            mae_cantons.append(MAE(Y[canton_idxs], Yp[canton_idxs]))\n",
    "            rmse_cantons.append(RMSE(Y[canton_idxs], Yp[canton_idxs]))\n",
    "        \n",
    "        print(f'{cutoff} {pn} MAE: {mae} | {mae_cantons}')\n",
    "        print(f'{cutoff} {pn} RMSE: {rmse} | {rmse_cantons}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COD_196 on DEEM_10k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5 volumes MAE: 8.806058367711302\n",
      "3.5 volumes RMSE: 14.843398697350736\n",
      "3.5 energies MAE: 36.22190421008153\n",
      "3.5 energies RMSE: 108.65834586518969\n",
      "6.0 volumes MAE: 3.223133406232656\n",
      "6.0 volumes RMSE: 10.968619050371599\n",
      "6.0 energies MAE: 29.63415327950305\n",
      "6.0 energies RMSE: 95.48433053527935\n"
     ]
    }
   ],
   "source": [
    "for cutoff in cutoffs:\n",
    "    for pn in ['volumes', 'energies']:\n",
    "        Y = np.loadtxt(f'../Processed_Data/COD_196/structure_{pn}.dat')\n",
    "        Yp = np.loadtxt(f'../Processed_Data/COD_196onDEEM_10k/Data/{cutoff}/predicted_structure_{pn}.dat')\n",
    "        Yp += Y_mean[pn]\n",
    "        mae = MAE(Y, Yp)\n",
    "        rmse = RMSE(Y, Yp)\n",
    "        \n",
    "        print(f'{cutoff} {pn} MAE: {mae}')\n",
    "        print(f'{cutoff} {pn} RMSE: {rmse}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
