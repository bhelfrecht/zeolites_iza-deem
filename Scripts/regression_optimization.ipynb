{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/home/helfrech/Tools/Toolbox/utils')\n",
    "\n",
    "# Maths\n",
    "import numpy as np\n",
    "\n",
    "# ML\n",
    "from kernels import gaussian_kernel\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.preprocessing import KernelCenterer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# Utilities\n",
    "import h5py\n",
    "from tempfile import mkdtemp\n",
    "from shutil import rmtree\n",
    "from tqdm.notebook import tqdm\n",
    "from tools import load_json, save_json\n",
    "import project_utils as utils\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train and test sets\n",
    "train_idxs = np.loadtxt('../Processed_Data/DEEM_330k/train.idxs', dtype=int)\n",
    "cv_idxs = np.loadtxt('../Processed_Data/DEEM_330k/cv_5.idxs', dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN TMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test sets (random DEEM)\n",
    "from numpy.random import default_rng\n",
    "idxs_delete = np.loadtxt('../Processed_Data/DEEM_330k/10kJmol_error.idxs', dtype=int)\n",
    "deem_10k_idxs = np.loadtxt('../Processed_Data/DEEM_330k/deem_10k.idxs', dtype=int)\n",
    "\n",
    "n_total = 331172\n",
    "n_train = 10000\n",
    "n_test = 250\n",
    "rng = default_rng(seed=11011)\n",
    "idxs = np.arange(0, n_total)\n",
    "idxs = np.delete(idxs, idxs_delete)\n",
    "rng.shuffle(idxs)\n",
    "train_idxs = idxs[0:n_train]\n",
    "test_idxs = idxs[n_train:n_train + n_test]\n",
    "\n",
    "cv_idxs = np.loadtxt('../Processed_Data/DEEM_330k/cv_5.idxs', dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# END TMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SOAP cutoffs\n",
    "soap_hyperparameters = load_json('../Processed_Data/soap_hyperparameters.json')   \n",
    "cutoffs = soap_hyperparameters['interaction_cutoff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make directory in which to store models\n",
    "os.makedirs('../Processed_Data/Models', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set property names for loading\n",
    "property_names = ['volumes', 'energies']\n",
    "\n",
    "# Load structure properties\n",
    "structure_properties = {}\n",
    "for pn in property_names:\n",
    "    structure_properties[pn] = np.loadtxt(f'../Processed_Data/DEEM_330k/Data/structure_{pn}.dat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use all defaults for the template parameters\n",
    "ridge_parameters = dict()\n",
    "\n",
    "# Regularization parameters for cross-validation\n",
    "regularizations = np.logspace(-12, 0, 13)\n",
    "parameter_grid = dict(ridge__regressor__alpha=regularizations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2063ef0bfe494fa3bc1a57574187325a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Cutoff', max=2.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Property', max=2.0, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.66057e-18): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=4.34198e-18): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=4.40539e-18): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=2.83784e-18): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=4.23673e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=4.22978e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=4.26919e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=4.38142e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=4.30239e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.66057e-18): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=4.34198e-18): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=4.40539e-18): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=2.83784e-18): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=4.23673e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=4.22978e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=4.26919e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=4.38142e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=4.30239e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Property', max=2.0, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.39509e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.3824e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.40297e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.39643e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.08835e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=8.88618e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=8.83027e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=9.03186e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=8.79685e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=8.80391e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.39509e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.3824e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.40297e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.39643e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.08835e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=8.88618e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=8.83027e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=9.03186e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=8.79685e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=8.80391e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Loop over cutoffs\n",
    "for cutoff in tqdm(cutoffs, desc='Cutoff', leave=True):\n",
    "    \n",
    "    # Set data directory\n",
    "    data_dir = f'../Processed_Data/DEEM_330k/Data/{cutoff}'\n",
    "    \n",
    "    # Read SOAPs in training set\n",
    "    sort_idxs = np.argsort(train_idxs) ### TMP\n",
    "    rev_idxs = np.argsort(sort_idxs) ### TMP\n",
    "    soaps = utils.load_hdf5(f'{data_dir}/soaps_power_full_avg_nonorm.hdf5', indices=train_idxs[sort_idxs]) ### REMOVE SORT IDXS\n",
    "    soaps = soaps[rev_idxs] ### TMP\n",
    "    \n",
    "    # Loop over properties\n",
    "    for pn in tqdm(property_names, desc='Property', leave=False):\n",
    "        property_label = pn.capitalize()\n",
    "        \n",
    "        # Set working directory\n",
    "        work_dir = f'../Processed_Data/Models/{cutoff}/Linear_Models/LR/{property_label}'\n",
    "        os.makedirs(work_dir, exist_ok=True)\n",
    "        \n",
    "        # Load the property values (just from the train set)\n",
    "        y = structure_properties[pn][train_idxs]\n",
    "         \n",
    "        # Cross validation pipeline\n",
    "        cache_dir = mkdtemp(dir=work_dir) # TODO: move this and rmtree outside the property loop?\n",
    "        pipeline = Pipeline(\n",
    "            [\n",
    "                ('norm_scaler', utils.NormScaler()), \n",
    "                ('ridge', TransformedTargetRegressor(\n",
    "                    regressor=Ridge(**ridge_parameters), \n",
    "                    transformer=utils.NormScaler()\n",
    "                ))\n",
    "            ],\n",
    "            memory=cache_dir\n",
    "        )\n",
    "        gscv = GridSearchCV(\n",
    "            pipeline, parameter_grid, \n",
    "            scoring=[\n",
    "                'neg_root_mean_squared_error', \n",
    "                'neg_mean_absolute_error'\n",
    "            ],\n",
    "            cv=utils.cv_generator(cv_idxs),\n",
    "            refit=False, return_train_score=True, error_score='raise'\n",
    "        )\n",
    "        gscv.fit(soaps, y)\n",
    "        rmtree(cache_dir)\n",
    "        \n",
    "        save_json(gscv.cv_results_, f'{work_dir}/cv_results.json', array_convert=True)\n",
    "        # TODO: check the optimal doesn't give an ill conditioned warning or doesn't converge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN TMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Optimal Parameters for 3.5 volumes mean_absolute_error-----\n",
      "neg_mean_absolute_error = -2.6278993636644223\n",
      "{'alpha': 0.0001}\n",
      "\n",
      "-----Optimal Parameters for 3.5 volumes root_mean_squared_error-----\n",
      "neg_root_mean_squared_error = -3.763467401447244\n",
      "{'alpha': 0.001}\n",
      "\n",
      "-----Optimal Parameters for 3.5 energies mean_absolute_error-----\n",
      "neg_mean_absolute_error = -0.6811454025198304\n",
      "{'alpha': 0.0001}\n",
      "\n",
      "-----Optimal Parameters for 3.5 energies root_mean_squared_error-----\n",
      "neg_root_mean_squared_error = -0.9701972225669557\n",
      "{'alpha': 0.0001}\n",
      "\n",
      "-----Optimal Parameters for 6.0 volumes mean_absolute_error-----\n",
      "neg_mean_absolute_error = -1.1184560899853364\n",
      "{'alpha': 0.01}\n",
      "\n",
      "-----Optimal Parameters for 6.0 volumes root_mean_squared_error-----\n",
      "neg_root_mean_squared_error = -1.7742455247921032\n",
      "{'alpha': 0.01}\n",
      "\n",
      "-----Optimal Parameters for 6.0 energies mean_absolute_error-----\n",
      "neg_mean_absolute_error = -0.11596155677192237\n",
      "{'alpha': 1e-07}\n",
      "\n",
      "-----Optimal Parameters for 6.0 energies root_mean_squared_error-----\n",
      "neg_root_mean_squared_error = -0.17825292076478727\n",
      "{'alpha': 1e-07}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract optimal parameters as a check\n",
    "\n",
    "# Loop over cutoffs\n",
    "for cutoff in cutoffs:\n",
    "    \n",
    "    # Loop over properties\n",
    "    for pn in property_names:\n",
    "        property_label = pn.capitalize()\n",
    "        \n",
    "        work_dir = f'../Processed_Data/Models/{cutoff}/Linear_Models/LR/{property_label}'\n",
    "        cv_results = load_json(f'{work_dir}/cv_results.json')\n",
    "        \n",
    "        # Loop over error types\n",
    "        for error, error_name in zip(\n",
    "            ['neg_mean_absolute_error', 'neg_root_mean_squared_error'],\n",
    "            ['mae', 'rmse']\n",
    "        ):\n",
    "        \n",
    "            idx = np.argmin(cv_results[f'rank_test_{error}'])\n",
    "            opt_parameters = utils.get_optimal_parameters(cv_results, error, **ridge_parameters)\n",
    "\n",
    "            # Print error and parameters\n",
    "            print(f'-----Optimal Parameters for {cutoff} {pn} {error[4:]}-----')\n",
    "            print(f'{error} =', cv_results[f'mean_test_{error}'][idx])\n",
    "            print(opt_parameters)\n",
    "            print('')\n",
    "            \n",
    "            # Save optimal parameters for easy access\n",
    "            save_json(opt_parameters, f'{work_dir}/ridge_parameters_{error_name}.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# END TMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Optimal Parameters for 3.5 volumes mean_absolute_error-----\n",
      "neg_mean_absolute_error = -2.549571216699533\n",
      "{'alpha': 0.0001}\n",
      "\n",
      "-----Optimal Parameters for 3.5 volumes root_mean_squared_error-----\n",
      "neg_root_mean_squared_error = -3.6876161795028453\n",
      "{'alpha': 0.0001}\n",
      "\n",
      "-----Optimal Parameters for 3.5 energies mean_absolute_error-----\n",
      "neg_mean_absolute_error = -0.6690029851874398\n",
      "{'alpha': 1e-05}\n",
      "\n",
      "-----Optimal Parameters for 3.5 energies root_mean_squared_error-----\n",
      "neg_root_mean_squared_error = -0.9511295920625198\n",
      "{'alpha': 0.001}\n",
      "\n",
      "-----Optimal Parameters for 6.0 volumes mean_absolute_error-----\n",
      "neg_mean_absolute_error = -1.0842773569634572\n",
      "{'alpha': 0.01}\n",
      "\n",
      "-----Optimal Parameters for 6.0 volumes root_mean_squared_error-----\n",
      "neg_root_mean_squared_error = -1.7692268855224387\n",
      "{'alpha': 0.01}\n",
      "\n",
      "-----Optimal Parameters for 6.0 energies mean_absolute_error-----\n",
      "neg_mean_absolute_error = -0.1200024862710221\n",
      "{'alpha': 1e-07}\n",
      "\n",
      "-----Optimal Parameters for 6.0 energies root_mean_squared_error-----\n",
      "neg_root_mean_squared_error = -0.2668239024734137\n",
      "{'alpha': 1e-06}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract optimal parameters as a check\n",
    "\n",
    "# Loop over cutoffs\n",
    "for cutoff in cutoffs:\n",
    "    \n",
    "    # Loop over properties\n",
    "    for pn in property_names:\n",
    "        property_label = pn.capitalize()\n",
    "        \n",
    "        work_dir = f'../Processed_Data/Models/{cutoff}/Linear_Models/LR/{property_label}'\n",
    "        cv_results = load_json(f'{work_dir}/cv_results.json')\n",
    "        \n",
    "        # Loop over error types\n",
    "        for error, error_name in zip(\n",
    "            ['neg_mean_absolute_error', 'neg_root_mean_squared_error'],\n",
    "            ['mae', 'rmse']\n",
    "        ):\n",
    "        \n",
    "            idx = np.argmin(cv_results[f'rank_test_{error}'])\n",
    "            opt_parameters = utils.get_optimal_parameters(cv_results, error, **ridge_parameters)\n",
    "\n",
    "            # Print error and parameters\n",
    "            print(f'-----Optimal Parameters for {cutoff} {pn} {error[4:]}-----')\n",
    "            print(f'{error} =', cv_results[f'mean_test_{error}'][idx])\n",
    "            print(opt_parameters)\n",
    "            print('')\n",
    "            \n",
    "            # Save optimal parameters for easy access\n",
    "            save_json(opt_parameters, f'{work_dir}/ridge_parameters_{error_name}.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use all defaults for the template parameters\n",
    "kernel_ridge_parameters = dict(kernel='precomputed')\n",
    "\n",
    "# Set ranges of kernel gamma (for Gaussian kernel) and regularization\n",
    "log_gammas = np.linspace(-3, 3, 7)\n",
    "##log_gammas = np.array([-2.0])\n",
    "\n",
    "regularizations = np.logspace(-12, 0, 13)\n",
    "##regularizations = np.array([1.0E-3, 1.0E-2])\n",
    "\n",
    "# Use the filenames of the kernels that we will be loading\n",
    "# in the \"hacked\" pipeline.\n",
    "# The gamma names for the kernel parsing will be set in the loop\n",
    "parameter_grid_base = dict(\n",
    "    ridge__regressor__alpha=regularizations, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5e5a3f0a1d444fda0822fc70ca88f94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Cutoff', max=2.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Gamma', max=1.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Gamma', max=1.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Loop over cutoffs\n",
    "for cutoff in tqdm(cutoffs, desc='Cutoff', leave=True):\n",
    "    \n",
    "    # Set data directory\n",
    "    data_dir = f'../Processed_Data/DEEM_10k/Data/{cutoff}'\n",
    "    model_dir = f'../Processed_Data/Models/{cutoff}/Kernel_Models/Gaussian'\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    \n",
    "    # Read SOAPs in training set\n",
    "    soaps = utils.load_hdf5(f'{data_dir}/soaps_power_full_nonorm.hdf5') # Use this\n",
    "    soaps = np.array([np.mean(soap, axis=0) for soap in soaps]) # Use this\n",
    "    ##str_idxs = [str(i).zfill(4) for i in range(0, len(train_idxs))]\n",
    "    ##soaps = utils.load_hdf5(f'{data_dir}/soaps.hdf5', datasets=str_idxs, concatenate=False)\n",
    "    \n",
    "    # Build a \"superkernel\": a concatenation of the train and test kernels\n",
    "    # (which we can store easily in memory and on disk) so that\n",
    "    # the pipeline doesn't compute whole new kernels for each CV set.\n",
    "    # We still have to compute a kernel for each gamma, though.\n",
    "    # We store the kernels named by the logarithm of the gamma parameter,\n",
    "    # so the filenames don't get ridiculous\n",
    "    ##XA = np.random.rand(10000, 1000)\n",
    "    for log_gamma in tqdm(log_gammas, desc='Gamma', leave=False):\n",
    "        gamma = 10 ** log_gamma\n",
    "        K = gaussian_kernel(soaps, soaps, gamma=gamma) # Use this\n",
    "        ##K = gaussian_kernel(XA, XA, gamma=gamma)\n",
    "        utils.save_hdf5(\n",
    "            f'{model_dir}/gaussian_kernel_{log_gamma}.hdf5', K, \n",
    "            attrs=dict(gamma=gamma, log_gamma=log_gamma), chunks=(100, 100)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacked CV indices so we can load and access the kernels by indexing\n",
    "# instead of recomputing them\n",
    "dummy_cv_idxs = np.arange(0, cv_idxs.shape[-1]).reshape((1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae2c6fa30d62421ba7dcc997bb9183e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Cutoff', max=2.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Property', max=2.0, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/pipeline.py:313: UserWarning: Persisting input arguments took 1.00s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/pipeline.py:313: UserWarning: Persisting input arguments took 0.66s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 4.960045460337438\n",
      "2000 6.539265800221978\n",
      "8000 0.007166189849750411\n",
      "8000 0.009392341815921012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/pipeline.py:313: UserWarning: Persisting input arguments took 0.99s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/pipeline.py:313: UserWarning: Persisting input arguments took 0.64s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 4.942079096059853\n",
      "2000 6.43008450991217\n",
      "8000 0.007181076673697766\n",
      "8000 0.009410821805014848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/pipeline.py:313: UserWarning: Persisting input arguments took 0.99s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/pipeline.py:313: UserWarning: Persisting input arguments took 0.63s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 4.810728029428967\n",
      "2000 6.299220004190456\n",
      "8000 0.007256557225164462\n",
      "8000 0.00949681243112259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/pipeline.py:313: UserWarning: Persisting input arguments took 1.01s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/pipeline.py:313: UserWarning: Persisting input arguments took 0.64s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 4.805670124528469\n",
      "2000 6.356051363793797\n",
      "8000 0.007248508979858779\n",
      "8000 0.009465932131919501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/pipeline.py:313: UserWarning: Persisting input arguments took 0.98s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/pipeline.py:313: UserWarning: Persisting input arguments took 0.62s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 4.9633533124433455\n",
      "2000 6.472562724901512\n",
      "8000 0.0071902838969953465\n",
      "8000 0.009417239885575432\n",
      "2000 4.95826557284866\n",
      "2000 6.537110212283552\n",
      "8000 0.07061094346583352\n",
      "8000 0.09254999552762669\n",
      "2000 4.939960350179164\n",
      "2000 6.4279299923430635\n",
      "8000 0.07075838101886131\n",
      "8000 0.09273302237765223\n",
      "2000 4.808946647991857\n",
      "2000 6.297193222363458\n",
      "8000 0.0715009391270776\n",
      "8000 0.09357841727293076\n",
      "2000 4.803984392860917\n",
      "2000 6.354536766719237\n",
      "8000 0.07142147281407321\n",
      "8000 0.09327289632744941\n",
      "2000 4.961639122401193\n",
      "2000 6.470757126592184\n",
      "8000 0.07084730371581265\n",
      "8000 0.09279416533548115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/pipeline.py:313: UserWarning: Persisting input arguments took 1.01s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/pipeline.py:313: UserWarning: Persisting input arguments took 0.63s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 4.402729097865448\n",
      "2000 5.285862854565544\n",
      "8000 0.006534903048649085\n",
      "8000 0.007825077597155774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/pipeline.py:313: UserWarning: Persisting input arguments took 1.00s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/pipeline.py:313: UserWarning: Persisting input arguments took 0.59s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 4.393761885876767\n",
      "2000 5.258442847327382\n",
      "8000 0.006548715298039497\n",
      "8000 0.007859924695296434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/pipeline.py:313: UserWarning: Persisting input arguments took 0.97s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/pipeline.py:313: UserWarning: Persisting input arguments took 0.65s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 4.507892878420929\n",
      "2000 5.371464495784244\n",
      "8000 0.006525489873679817\n",
      "8000 0.007820004358709193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/pipeline.py:313: UserWarning: Persisting input arguments took 1.00s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/pipeline.py:313: UserWarning: Persisting input arguments took 0.64s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 4.4605204733422354\n",
      "2000 5.346656771817301\n",
      "8000 0.006541468455573067\n",
      "8000 0.007822420139648787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/pipeline.py:313: UserWarning: Persisting input arguments took 1.00s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/pipeline.py:313: UserWarning: Persisting input arguments took 0.65s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 4.474940789064357\n",
      "2000 5.346606667668517\n",
      "8000 0.006523312979016055\n",
      "8000 0.007825119702256559\n",
      "2000 4.4016397013740205\n",
      "2000 5.284119726077778\n",
      "8000 0.06439958844936496\n",
      "8000 0.07710759582966766\n",
      "2000 4.392841109567889\n",
      "2000 5.256945454264224\n",
      "8000 0.06453424778184468\n",
      "8000 0.07744878262945074\n",
      "2000 4.506844367297403\n",
      "2000 5.369948960334716\n",
      "8000 0.06430455626680691\n",
      "8000 0.07705408233542767\n",
      "2000 4.45940358680704\n",
      "2000 5.344893658102849\n",
      "8000 0.06446240443279772\n",
      "8000 0.07707976299419332\n",
      "2000 4.473880183240371\n",
      "2000 5.345075052320698\n",
      "8000 0.06428354117143477\n",
      "8000 0.07710586630137903\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Property', max=2.0, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/pipeline.py:313: UserWarning: Persisting input arguments took 1.00s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/pipeline.py:313: UserWarning: Persisting input arguments took 0.65s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 5.0295373215385535\n",
      "2000 6.578949014165565\n",
      "8000 0.0071237610072918435\n",
      "8000 0.009371106637919811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/pipeline.py:313: UserWarning: Persisting input arguments took 0.96s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/pipeline.py:313: UserWarning: Persisting input arguments took 0.65s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 4.866968397693262\n",
      "2000 6.381358290763396\n",
      "8000 0.007177524667246514\n",
      "8000 0.009461465820280283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/pipeline.py:313: UserWarning: Persisting input arguments took 0.99s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/pipeline.py:313: UserWarning: Persisting input arguments took 0.64s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 4.720749395931691\n",
      "2000 6.181133799609303\n",
      "8000 0.007248295469694294\n",
      "8000 0.009529677971386725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/pipeline.py:313: UserWarning: Persisting input arguments took 1.02s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/pipeline.py:313: UserWarning: Persisting input arguments took 0.59s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 4.854658380693583\n",
      "2000 6.472832879565431\n",
      "8000 0.007211631196156998\n",
      "8000 0.009424475490826839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/pipeline.py:313: UserWarning: Persisting input arguments took 0.99s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/pipeline.py:313: UserWarning: Persisting input arguments took 0.63s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 4.960818163028237\n",
      "2000 6.456212171494541\n",
      "8000 0.007148915733277307\n",
      "8000 0.009427737666256233\n",
      "2000 5.027518496865081\n",
      "2000 6.576726872018838\n",
      "8000 0.07019206842427306\n",
      "8000 0.09234030411041187\n",
      "2000 4.865244064571327\n",
      "2000 6.379471386984439\n",
      "8000 0.07072064166630189\n",
      "8000 0.09322789631353146\n",
      "2000 4.7190857474305865\n",
      "2000 6.179348431313144\n",
      "8000 0.0714185761465637\n",
      "8000 0.09390258293775754\n",
      "2000 4.852723462190191\n",
      "2000 6.47086154223445\n",
      "8000 0.07105672457290399\n",
      "8000 0.09286492236226893\n",
      "2000 4.958976149809162\n",
      "2000 6.454169674809251\n",
      "8000 0.07044073261087204\n",
      "8000 0.0928980121254763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/pipeline.py:313: UserWarning: Persisting input arguments took 0.97s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/pipeline.py:313: UserWarning: Persisting input arguments took 0.63s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 4.402480373070501\n",
      "2000 5.264167600257628\n",
      "8000 0.006593520372734929\n",
      "8000 0.007901001921687845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/pipeline.py:313: UserWarning: Persisting input arguments took 0.98s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/pipeline.py:313: UserWarning: Persisting input arguments took 0.64s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 4.416118717740299\n",
      "2000 5.2731037753995915\n",
      "8000 0.006588975990578547\n",
      "8000 0.007900375624650988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/pipeline.py:313: UserWarning: Persisting input arguments took 1.00s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/pipeline.py:313: UserWarning: Persisting input arguments took 0.64s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 4.515232739267379\n",
      "2000 5.424421802057503\n",
      "8000 0.006555688084134317\n",
      "8000 0.00783352437125129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/pipeline.py:313: UserWarning: Persisting input arguments took 0.97s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/pipeline.py:313: UserWarning: Persisting input arguments took 0.63s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 4.496065842492748\n",
      "2000 5.345421404588377\n",
      "8000 0.006576645948995292\n",
      "8000 0.007861375018359547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/pipeline.py:313: UserWarning: Persisting input arguments took 0.99s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/sklearn/pipeline.py:313: UserWarning: Persisting input arguments took 0.64s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 4.486501334937917\n",
      "2000 5.392068834042245\n",
      "8000 0.006550265980625226\n",
      "8000 0.007850006534127258\n",
      "2000 4.401412512842515\n",
      "2000 5.262705825404646\n",
      "8000 0.06497304630108897\n",
      "8000 0.0778512897570538\n",
      "2000 4.41522173747049\n",
      "2000 5.271624863803656\n",
      "8000 0.06492891516984674\n",
      "8000 0.07784542723723505\n",
      "2000 4.514112441602189\n",
      "2000 5.42264727172415\n",
      "8000 0.0646010844020409\n",
      "8000 0.07718730290933713\n",
      "2000 4.494938557694049\n",
      "2000 5.343808076466818\n",
      "8000 0.06480752593875196\n",
      "8000 0.07746236419478778\n",
      "2000 4.485312168294686\n",
      "2000 5.390281419199412\n",
      "8000 0.0645489751580883\n",
      "8000 0.07735134825282045\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Optimize hyperparameters\n",
    "\n",
    "# Loop over cutoffs\n",
    "for cutoff in tqdm(cutoffs, desc='Cutoff', leave=True):\n",
    "    \n",
    "    # Set data directory\n",
    "    model_dir = f'../Processed_Data/Models/{cutoff}/Kernel_Models/Gaussian'\n",
    "    \n",
    "    parameter_grid = deepcopy(parameter_grid_base)\n",
    "    parameter_grid['kernel_loader__filename'] = \\\n",
    "        [f'{model_dir}/gaussian_kernel_{log_gamma}.hdf5' for log_gamma in log_gammas]\n",
    "          \n",
    "    # Loop over properties\n",
    "    for pn in tqdm(property_names, desc='Property', leave=False):\n",
    "        property_label = pn.capitalize()\n",
    "        \n",
    "        # Set working directory\n",
    "        work_dir = f'{model_dir}/KRR/{property_label}'\n",
    "        os.makedirs(work_dir, exist_ok=True)\n",
    "                \n",
    "        # Load the property values (just from the train set)\n",
    "        y = structure_properties[pn][train_idxs]\n",
    "        \n",
    "        # \"Hacked\" pipeline: instead of recomputing the expensive kernels\n",
    "        # at each CV iteration, we will fit instead with a set of indices\n",
    "        # and use the filename containing the kernel at a particular\n",
    "        # gamma as a hyperparameter for KernelLoader, which will\n",
    "        # load the kernel at initialization.\n",
    "                \n",
    "        # NOTE: can't just use the custom kernel as a callable\n",
    "        # to KernelRidge, as the custom kernel necessarily operates on 2D arrays\n",
    "        # of the features for all environments in a given structure,\n",
    "        # whereas the callable must operate on pairs of samples.\n",
    "        # The KernelLoader/KernelConstructor is used instead\n",
    "        cache_dir = mkdtemp(dir=work_dir)\n",
    "        pipeline = Pipeline(\n",
    "            [\n",
    "                ('kernel_loader', utils.KernelLoader()),\n",
    "                ('kernel_norm_scaler', utils.KernelNormScaler()), \n",
    "                ('ridge', TransformedTargetRegressor(\n",
    "                    regressor=KernelRidge(**kernel_ridge_parameters),\n",
    "                    transformer=utils.SampleSelector(X=y, model=utils.NormScaler()),\n",
    "                    check_inverse=False\n",
    "                ))\n",
    "            ],\n",
    "            memory=cache_dir\n",
    "        )\n",
    "        \n",
    "        # \"Hacked\" CV: since we want to access the kernels via indices,\n",
    "        # we fit the CV with cv_indices, and the cv_generator \n",
    "        # is used to pick out the correct folds\n",
    "        gscv = GridSearchCV(\n",
    "            pipeline, parameter_grid, \n",
    "            scoring=dict(\n",
    "                neg_mean_absolute_error=make_scorer(\n",
    "                    utils.score_by_index,\n",
    "                    greater_is_better=False,\n",
    "                    y=y, scorer=mean_absolute_error\n",
    "                ),\n",
    "                neg_root_mean_squared_error=make_scorer(\n",
    "                    utils.score_by_index,\n",
    "                    greater_is_better=False,\n",
    "                    y=y, scorer=mean_squared_error,\n",
    "                    squared=False\n",
    "                )\n",
    "            ),\n",
    "            cv=utils.cv_generator(dummy_cv_idxs),\n",
    "            refit=False, return_train_score=True, error_score='raise'\n",
    "        )\n",
    "        gscv.fit(cv_idxs.T, cv_idxs.T)\n",
    "        save_json(gscv.cv_results_, f'{work_dir}/cv_results.json', array_convert=True)\n",
    "        rmtree(cache_dir)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dummy_train_idxs = [1, 2, 3, 4]\n",
    "dummy_test_idxs = [0]\n",
    "\n",
    "y = structure_properties['energies'][train_idxs]\n",
    "y_train_init = y[cv_idxs.T[dummy_train_idxs].flatten()]\n",
    "y_test_init = y[cv_idxs.T[dummy_test_idxs].flatten()]\n",
    "\n",
    "kernel_loader = utils.KernelLoader(\n",
    "    filename='../Processed_Data/Models/6.0/Kernel_Models/Gaussian/gaussian_kernel_-2.0.hdf5'\n",
    ")\n",
    "kernel_scaler = utils.KernelNormScaler()\n",
    "ttr = TransformedTargetRegressor(\n",
    "    regressor=KernelRidge(alpha=1.0E-2, kernel='precomputed'),\n",
    "    transformer=utils.SampleSelector(X=y, model=utils.NormScaler()),\n",
    "    check_inverse=False\n",
    ")\n",
    "\n",
    "kernel_loader.fit(cv_idxs.T[dummy_train_idxs])\n",
    "K_train = kernel_loader.transform(cv_idxs.T[dummy_train_idxs])\n",
    "K_test = kernel_loader.transform(cv_idxs.T[dummy_test_idxs])\n",
    "\n",
    "kernel_scaler.fit(K_train)\n",
    "K_train = kernel_scaler.transform(K_train)\n",
    "K_test = kernel_scaler.transform(K_test)\n",
    "\n",
    "ttr.fit(K_train, cv_idxs.T[dummy_train_idxs].flatten())\n",
    "y_train_pred = ttr.predict(K_train)\n",
    "y_test_pred = ttr.predict(K_test)\n",
    "\n",
    "print(mean_absolute_error(y_train_init, y_train_pred))\n",
    "print(mean_absolute_error(y_test_init, y_test_pred))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dummy_train_idxs = [1, 2, 3, 4]\n",
    "dummy_test_idxs = [0]\n",
    "\n",
    "y = structure_properties['energies'][train_idxs]\n",
    "y_train_init = y[cv_idxs.T[dummy_train_idxs].flatten()]\n",
    "y_test_init = y[cv_idxs.T[dummy_test_idxs].flatten()]\n",
    "\n",
    "kernel_loader = utils.KernelLoader(\n",
    "    filename='../Processed_Data/Models/6.0/Kernel_Models/Gaussian/gaussian_kernel_-2.0.hdf5'\n",
    ")\n",
    "kernel_scaler = utils.KernelNormScaler()\n",
    "ttr = TransformedTargetRegressor(\n",
    "    regressor=KernelRidge(alpha=1.0E-2, kernel='precomputed'),\n",
    "    transformer=utils.NormScaler(),\n",
    ")\n",
    "sample_selector = utils.SampleSelector(X=y)\n",
    "\n",
    "kernel_loader.fit(cv_idxs.T[dummy_train_idxs])\n",
    "K_train = kernel_loader.transform(cv_idxs.T[dummy_train_idxs])\n",
    "K_test = kernel_loader.transform(cv_idxs.T[dummy_test_idxs])\n",
    "\n",
    "kernel_scaler.fit(K_train)\n",
    "K_train = kernel_scaler.transform(K_train)\n",
    "K_test = kernel_scaler.transform(K_test)\n",
    "\n",
    "ttr.fit(K_train, sample_selector.transform(cv_idxs.T[dummy_train_idxs]))\n",
    "y_train_pred = ttr.predict(K_train)\n",
    "y_test_pred = ttr.predict(K_test)\n",
    "\n",
    "print(mean_absolute_error(y_train_init, y_train_pred))\n",
    "print(mean_absolute_error(y_test_init, y_test_pred))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dummy_train_idxs = [1, 2, 3, 4]\n",
    "dummy_test_idxs = [0]\n",
    "\n",
    "y = structure_properties['energies'][train_idxs]\n",
    "y_train_init = y[cv_idxs.T[dummy_train_idxs].flatten()]\n",
    "y_test_init = y[cv_idxs.T[dummy_test_idxs].flatten()]\n",
    "\n",
    "kernel_loader = utils.KernelLoader(\n",
    "    filename='../Processed_Data/Models/6.0/Kernel_Models/Gaussian/gaussian_kernel_-2.0.hdf5'\n",
    ")\n",
    "kernel_scaler = utils.KernelNormScaler()\n",
    "krr = KernelRidge(alpha=1.0E-2, kernel='precomputed')\n",
    "sample_selector = utils.SampleSelector(X=y, model=utils.NormScaler())\n",
    "\n",
    "kernel_loader.fit(cv_idxs.T[dummy_train_idxs])\n",
    "K_train = kernel_loader.transform(cv_idxs.T[dummy_train_idxs])\n",
    "K_test = kernel_loader.transform(cv_idxs.T[dummy_test_idxs])\n",
    "\n",
    "kernel_scaler.fit(K_train)\n",
    "K_train = kernel_scaler.transform(K_train)\n",
    "K_test = kernel_scaler.transform(K_test)\n",
    "\n",
    "sample_selector.fit(cv_idxs.T[dummy_train_idxs])\n",
    "y_train = sample_selector.transform(cv_idxs.T[dummy_train_idxs])\n",
    "y_test = sample_selector.transform(cv_idxs.T[dummy_test_idxs])\n",
    "\n",
    "krr.fit(K_train, y_train)\n",
    "y_train_pred = krr.predict(K_train)\n",
    "y_test_pred = krr.predict(K_test)\n",
    "\n",
    "y_train_pred = sample_selector.inverse_transform(y_train_pred)\n",
    "y_test_pred = sample_selector.inverse_transform(y_test_pred)\n",
    "\n",
    "print(mean_absolute_error(y_train_init, y_train_pred))\n",
    "print(mean_absolute_error(y_test_init, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Optimal Parameters for 3.5 volumes mean_absolute_error-----\n",
      "neg_mean_absolute_error = -50.46811285596522\n",
      "{'kernel': 'precomputed', 'filename': '../Processed_Data/Models/3.5/Kernel_Models/Gaussian/gaussian_kernel_1.0.hdf5', 'alpha': 1e-12}\n",
      "\n",
      "-----Optimal Parameters for 3.5 volumes root_mean_squared_error-----\n",
      "neg_root_mean_squared_error = -50.836986007724846\n",
      "{'kernel': 'precomputed', 'filename': '../Processed_Data/Models/3.5/Kernel_Models/Gaussian/gaussian_kernel_1.0.hdf5', 'alpha': 1e-12}\n",
      "\n",
      "-----Optimal Parameters for 3.5 energies mean_absolute_error-----\n",
      "neg_mean_absolute_error = -12395.5157030061\n",
      "{'kernel': 'precomputed', 'filename': '../Processed_Data/Models/3.5/Kernel_Models/Gaussian/gaussian_kernel_1.0.hdf5', 'alpha': 1e-12}\n",
      "\n",
      "-----Optimal Parameters for 3.5 energies root_mean_squared_error-----\n",
      "neg_root_mean_squared_error = -12395.516743897222\n",
      "{'kernel': 'precomputed', 'filename': '../Processed_Data/Models/3.5/Kernel_Models/Gaussian/gaussian_kernel_1.0.hdf5', 'alpha': 1e-12}\n",
      "\n",
      "-----Optimal Parameters for 6.0 volumes mean_absolute_error-----\n",
      "neg_mean_absolute_error = -50.46811285596523\n",
      "{'kernel': 'precomputed', 'filename': '../Processed_Data/Models/6.0/Kernel_Models/Gaussian/gaussian_kernel_1.0.hdf5', 'alpha': 1e-12}\n",
      "\n",
      "-----Optimal Parameters for 6.0 volumes root_mean_squared_error-----\n",
      "neg_root_mean_squared_error = -50.83698600772485\n",
      "{'kernel': 'precomputed', 'filename': '../Processed_Data/Models/6.0/Kernel_Models/Gaussian/gaussian_kernel_1.0.hdf5', 'alpha': 1e-12}\n",
      "\n",
      "-----Optimal Parameters for 6.0 energies mean_absolute_error-----\n",
      "neg_mean_absolute_error = -12395.5157030061\n",
      "{'kernel': 'precomputed', 'filename': '../Processed_Data/Models/6.0/Kernel_Models/Gaussian/gaussian_kernel_1.0.hdf5', 'alpha': 1e-12}\n",
      "\n",
      "-----Optimal Parameters for 6.0 energies root_mean_squared_error-----\n",
      "neg_root_mean_squared_error = -12395.516743897222\n",
      "{'kernel': 'precomputed', 'filename': '../Processed_Data/Models/6.0/Kernel_Models/Gaussian/gaussian_kernel_1.0.hdf5', 'alpha': 1e-12}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract optimal parameters as a check\n",
    "\n",
    "# Loop over cutoffs\n",
    "for cutoff in cutoffs:\n",
    "    if cutoff != 3.5:\n",
    "        continue\n",
    "    \n",
    "    # Loop over properties\n",
    "    for pn in property_names:\n",
    "        property_label = pn.capitalize()\n",
    "        \n",
    "        work_dir = f'../Processed_Data/Models/{cutoff}/Kernel_Models/Gaussian/KRR/{property_label}'\n",
    "        cv_results = load_json(f'{work_dir}/cv_results.json')\n",
    "        \n",
    "        # Loop over error types\n",
    "        for error, error_name in zip(\n",
    "            ['neg_mean_absolute_error', 'neg_root_mean_squared_error'],\n",
    "            ['mae', 'rmse']\n",
    "        ):\n",
    "        \n",
    "            idx = np.argmin(cv_results[f'rank_test_{error}'])\n",
    "            opt_parameters = utils.get_optimal_parameters(cv_results, error, **kernel_ridge_parameters)\n",
    "\n",
    "            # Print error and parameters\n",
    "            print(f'-----Optimal Parameters for {cutoff} {pn} {error[4:]}-----')\n",
    "            print(f'{error} =', cv_results[f'mean_test_{error}'][idx])\n",
    "            print(opt_parameters)\n",
    "            print('')\n",
    "            \n",
    "            # Save optimal parameters for easy access\n",
    "            save_json(opt_parameters, f'{work_dir}/ridge_parameters_{error_name}.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
