{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Maths\n",
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "# ML\n",
    "from soap import extract_species_pair_groups\n",
    "\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, roc_auc_score\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# Utilities\n",
    "import h5py\n",
    "import json\n",
    "import itertools\n",
    "from tempfile import mkdtemp\n",
    "from shutil import rmtree\n",
    "from copy import deepcopy\n",
    "from tqdm.auto import tqdm\n",
    "import project_utils as utils\n",
    "from tools import load_json, save_json\n",
    "\n",
    "# Import COSMO style toolkit\n",
    "import cosmoplot.colorbars as cosmocbars\n",
    "import cosmoplot.style as cosmostyle\n",
    "\n",
    "cosmostyle.set_style('article')\n",
    "colorList = cosmostyle.color_cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "deem_volumes = np.loadtxt('../Processed_Data/DEEM_330k/Data/structure_volumes.dat')\n",
    "deem_energies = np.loadtxt('../Processed_Data/DEEM_330k/Data/structure_energies.dat')\n",
    "# deem_n_Si = np.loadtxt('../Processed_Data/DEEM_330k/Data/n_Si.dat', dtype=int)\n",
    "deem_ev = np.column_stack([deem_volumes, deem_energies])\n",
    "n_deem = len(deem_volumes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "iza_volumes = np.loadtxt('../Processed_Data/IZA_230/Data/structure_volumes.dat')\n",
    "iza_energies = np.loadtxt('../Processed_Data/IZA_230/Data/structure_energies.dat')\n",
    "# iza_n_Si = np.loadtxt('../Processed_Data/IZA_230/Data/n_Si.dat', dtype=int)\n",
    "iza_ev = np.column_stack([iza_volumes, iza_energies])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train sets for IZA and Deem\n",
    "iza_train_idxs = np.loadtxt('../Processed_Data/IZA_230/svm_train.idxs', dtype=int)\n",
    "iza_sort_idxs = np.argsort(iza_train_idxs)\n",
    "iza_unsort_idxs = np.argsort(iza_sort_idxs)\n",
    "deem_train_idxs = np.loadtxt('../Processed_Data/DEEM_330k/svm_train.idxs', dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build energy-volume features\n",
    "ev = np.vstack([\n",
    "    iza_ev[iza_train_idxs],\n",
    "    deem_ev[deem_train_idxs]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cantons for IZA and Deem\n",
    "iza_cantons = np.loadtxt('../Raw_Data/IZA_230/cantons_compositions.dat', usecols=1, dtype=int)\n",
    "deem_cantons_2 = np.loadtxt('../Processed_Data/DEEM_330k/Data/cantons_2-class.dat', dtype=int)\n",
    "deem_cantons_4 = np.loadtxt('../Processed_Data/DEEM_330k/Data/cantons_4-class.dat', dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build set of \"master\" canton labels\n",
    "cantons = {}\n",
    "\n",
    "cantons[4] = np.concatenate((\n",
    "    iza_cantons[iza_train_idxs], \n",
    "    deem_cantons_4[deem_train_idxs]\n",
    "))\n",
    "\n",
    "cantons[2] = np.concatenate((\n",
    "    np.ones(len(iza_train_idxs), dtype=int),\n",
    "    deem_cantons_2[deem_train_idxs]\n",
    "))\n",
    "\n",
    "# Build set of class weights (by sample) for centering and scaling\n",
    "class_weights = {n_cantons: utils.balanced_class_weights(cantons[n_cantons]) for n_cantons in (2, 4)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = '../Processed_Data/Models'\n",
    "\n",
    "deem_name = 'DEEM_330k'\n",
    "iza_name = 'IZA_230'\n",
    "deem_dir = f'../Processed_Data/{deem_name}/Data'\n",
    "iza_dir = f'../Processed_Data/{iza_name}/Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV splits\n",
    "n_splits = 2\n",
    "\n",
    "# When using the OneVsRestClassifier, \n",
    "# n_classes binary problems are passed to SVC, \n",
    "# and the decision function shape doesn't have an impact\n",
    "svc_parameters = dict(\n",
    "    kernel='precomputed',\n",
    "    decision_function_shape='ovo',\n",
    "    class_weight='balanced',\n",
    "    tol=1.0E-3,\n",
    "    cache_size=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear model setup\n",
    "df_types = ['OvR', 'OvO']\n",
    "# df_types = ['OvO']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize LinearSVC parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularization parameters for cross-validation\n",
    "C = np.logspace(-4, 4, 9)\n",
    "parameter_grid = dict(\n",
    "    OvR=dict(svc__estimator__C=C),\n",
    "    OvO=dict(svc__C=C)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dd15555645f434cb99a94a9226806d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='DF', max=2.0, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Classes', max=2.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Classes', max=2.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for df_type in tqdm(df_types, desc='DF', leave=True):    \n",
    "    work_dir = f'{model_dir}/Classical/LSVC/{df_type}'\n",
    "    \n",
    "    os.makedirs(work_dir, exist_ok=True)\n",
    "    \n",
    "    for n_cantons in tqdm((2, 4), desc='Classes', leave=False):\n",
    "\n",
    "        # IZA + Deem classification\n",
    "        svc = SVC(**svc_parameters)\n",
    "        if df_type == 'OvR':\n",
    "            svc = OneVsRestClassifier(svc)\n",
    "\n",
    "        pipeline = utils.ClassBalancedPipeline(\n",
    "            [\n",
    "                ('norm_scaler', utils.StandardNormScaler(featurewise=True)),\n",
    "                ('kernel_constructor', utils.KernelConstructor()),\n",
    "                ('svc', svc)\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        gscv = GridSearchCV(\n",
    "            pipeline, parameter_grid[df_type],\n",
    "            scoring=[\n",
    "                'accuracy', 'balanced_accuracy',\n",
    "            ],\n",
    "            cv=StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0),\n",
    "            refit=False, return_train_score=True, error_score='raise', n_jobs=4\n",
    "        )\n",
    "        #fit_params = {'norm_scaler__sample_weight': class_weights[n_cantons]}\n",
    "        fit_params = {'keys': ['norm_scaler__sample_weight']}\n",
    "        gscv.fit(ev, cantons[n_cantons], **fit_params)\n",
    "\n",
    "        # Prepare outputs\n",
    "        output_dir = f'{n_cantons}-Class/Energy-Volume'\n",
    "        os.makedirs(f'{work_dir}/{output_dir}', exist_ok=True)\n",
    "        save_json(gscv.cv_results_, f'{work_dir}/{output_dir}/cv_results.json', array_convert=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the cross-validated parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Optimal Parameters for OvR 2 -----\n",
      "accuracy = 0.8629490110211938\n",
      "{'kernel': 'precomputed', 'decision_function_shape': 'ovo', 'class_weight': 'balanced', 'tol': 0.001, 'cache_size': 1000, 'C': 10000.0}\n",
      "\n",
      "balanced_accuracy = 0.8829976746226438\n",
      "{'kernel': 'precomputed', 'decision_function_shape': 'ovo', 'class_weight': 'balanced', 'tol': 0.001, 'cache_size': 1000, 'C': 10000.0}\n",
      "\n",
      "-----Optimal Parameters for OvR 4 -----\n",
      "accuracy = 0.8099472383498998\n",
      "{'kernel': 'precomputed', 'decision_function_shape': 'ovo', 'class_weight': 'balanced', 'tol': 0.001, 'cache_size': 1000, 'C': 100.0}\n",
      "\n",
      "balanced_accuracy = 0.5622278472361139\n",
      "{'kernel': 'precomputed', 'decision_function_shape': 'ovo', 'class_weight': 'balanced', 'tol': 0.001, 'cache_size': 1000, 'C': 0.01}\n",
      "\n",
      "-----Optimal Parameters for OvO 2 -----\n",
      "accuracy = 0.8629490110211938\n",
      "{'kernel': 'precomputed', 'decision_function_shape': 'ovo', 'class_weight': 'balanced', 'tol': 0.001, 'cache_size': 1000, 'C': 10000.0}\n",
      "\n",
      "balanced_accuracy = 0.8829976746226438\n",
      "{'kernel': 'precomputed', 'decision_function_shape': 'ovo', 'class_weight': 'balanced', 'tol': 0.001, 'cache_size': 1000, 'C': 10000.0}\n",
      "\n",
      "-----Optimal Parameters for OvO 4 -----\n",
      "accuracy = 0.7692058554629126\n",
      "{'kernel': 'precomputed', 'decision_function_shape': 'ovo', 'class_weight': 'balanced', 'tol': 0.001, 'cache_size': 1000, 'C': 1000.0}\n",
      "\n",
      "balanced_accuracy = 0.5406125672204039\n",
      "{'kernel': 'precomputed', 'decision_function_shape': 'ovo', 'class_weight': 'balanced', 'tol': 0.001, 'cache_size': 1000, 'C': 0.1}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# IZA + DEEM classification\n",
    "for df_type in df_types:\n",
    "    work_dir = f'{model_dir}/Classical/LSVC/{df_type}'\n",
    "    for n_cantons in (2, 4):\n",
    "        result_dir = f'{n_cantons}-Class/Energy-Volume'\n",
    "        cv_results = load_json(f'{work_dir}/{result_dir}/cv_results.json')\n",
    "        print(f'-----Optimal Parameters for {df_type} {n_cantons} -----')\n",
    "#                 fig, axs = plt.subplots(1, 2)        \n",
    "\n",
    "        for score in ('accuracy', 'balanced_accuracy'):\n",
    "#                 for sdx, score in enumerate(('accuracy', 'balanced_accuracy')):\n",
    "            idx = np.argmin(cv_results[f'rank_test_{score}'])\n",
    "            opt_parameters = utils.get_optimal_parameters(cv_results, score, **svc_parameters)\n",
    "            print(f'{score} =', cv_results[f'mean_test_{score}'][idx])\n",
    "            print(opt_parameters)\n",
    "            print('')\n",
    "#                     axs[sdx].semilogx(\n",
    "#                         np.array([list(d.values()) for d in cv_results['params']]).flatten(),\n",
    "#                         cv_results[f'mean_test_{score}']\n",
    "#                     )\n",
    "#                     axs[sdx].set_title(f'{cutoff} {spectrum_type} {group_name} {n_cantons}')\n",
    "\n",
    "            save_json(opt_parameters, f'{work_dir}/{result_dir}/svc_parameters_{score}.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f856f0e3c2ad412fbf85a8c10bd6952b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='DF', max=2.0, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Classes', max=2.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Batch', max=17.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Batch', max=17.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Classes', max=2.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Batch', max=17.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Batch', max=17.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for df_type in tqdm(df_types, desc='DF', leave=True):   \n",
    "    linear_dir = f'{model_dir}/Classical/LSVC/{df_type}'\n",
    "\n",
    "    # Prepare batches for SVM\n",
    "    n_samples_330k = n_deem\n",
    "    n_batches = n_samples_330k // batch_size\n",
    "    if n_samples_330k % batch_size > 0:\n",
    "        n_batches += 1\n",
    "\n",
    "    for n_cantons in tqdm((2, 4), desc='Classes', leave=False):\n",
    "\n",
    "        # Prepare outputs\n",
    "        output_dir = f'LSVC/{df_type}/{n_cantons}-Class/Energy-Volume'\n",
    "\n",
    "        os.makedirs(f'{deem_dir}/Classical/{output_dir}', exist_ok=True)\n",
    "        os.makedirs(f'{iza_dir}/Classical/{output_dir}', exist_ok=True)\n",
    "\n",
    "        parameter_dir = f'{linear_dir}/{n_cantons}-Class/Energy-Volume'\n",
    "\n",
    "        svc_parameters = load_json(f'{parameter_dir}/svc_parameters_balanced_accuracy.json')\n",
    "\n",
    "        # IZA+DEEM classification\n",
    "        svc = SVC(**svc_parameters)\n",
    "        if df_type == 'OvR':\n",
    "            svc = OneVsRestClassifier(svc, n_jobs=4)\n",
    "\n",
    "        pipeline = Pipeline(\n",
    "            [\n",
    "                ('norm_scaler', utils.StandardNormScaler(featurewise=True)),\n",
    "                ('kernel_constructor', utils.KernelConstructor()),\n",
    "                ('svc', svc)\n",
    "            ],\n",
    "        )\n",
    "        fit_params = {'norm_scaler__sample_weight': class_weights[n_cantons]}\n",
    "        pipeline.fit(ev, cantons[n_cantons], **fit_params)\n",
    "\n",
    "        # Read the IZA structures and compute decision functions\n",
    "        # and canton predictions\n",
    "        iza_dfs = pipeline.decision_function(iza_ev)\n",
    "        iza_predicted_cantons = pipeline.predict(iza_ev)\n",
    "\n",
    "        np.savetxt(f'{iza_dir}/Classical/{output_dir}/svc_structure_dfs.dat', iza_dfs)\n",
    "        np.savetxt(f'{iza_dir}/Classical/{output_dir}/svc_structure_cantons.dat', iza_predicted_cantons, fmt='%d')\n",
    "\n",
    "        # Read the DEEM structures and compute decision functions\n",
    "        # and canton predictions\n",
    "        if n_cantons == 2:\n",
    "            deem_dfs = np.zeros(n_deem)\n",
    "        else:\n",
    "            if df_type == 'OvR':\n",
    "                deem_dfs = np.zeros((n_deem, n_cantons))\n",
    "            elif df_type == 'OvO':\n",
    "                deem_dfs = np.zeros((n_deem, n_cantons * (n_cantons - 1) // 2))\n",
    "\n",
    "        deem_predicted_cantons = np.zeros(n_deem)\n",
    "\n",
    "        for i in tqdm(range(0, n_batches), desc='Batch', leave=False):\n",
    "            batch_slice = slice(i * batch_size, (i + 1) * batch_size)\n",
    "\n",
    "            deem_330k_batch = deem_ev[batch_slice]\n",
    "            deem_dfs[batch_slice] = pipeline.decision_function(deem_330k_batch)\n",
    "            deem_predicted_cantons[batch_slice] = pipeline.predict(deem_330k_batch)\n",
    "\n",
    "        np.savetxt(f'{deem_dir}/Classical/{output_dir}/svc_structure_dfs.dat', deem_dfs)\n",
    "        np.savetxt(f'{deem_dir}/Classical/{output_dir}/svc_structure_cantons.dat', deem_predicted_cantons, fmt='%d')\n",
    "\n",
    "        # Save the SVC model and the scaler\n",
    "        # We don't save the KernelConstructor b/c it is really big\n",
    "        save_json(pipeline.named_steps['norm_scaler'].__dict__, f'{parameter_dir}/norm_scaler.json', array_convert=True)\n",
    "        save_json(pipeline.named_steps['svc'].__dict__, f'{parameter_dir}/svc.json', array_convert=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
