{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In /home/helfrech/.config/matplotlib/stylelib/cosmo.mplstyle: \n",
      "The savefig.frameon rcparam was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
      "In /home/helfrech/.config/matplotlib/stylelib/cosmoLarge.mplstyle: \n",
      "The savefig.frameon rcparam was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
      "/home/helfrech/ENVIRONMENTS/ZEOLITES/lib/python3.6/_collections_abc.py:841: MatplotlibDeprecationWarning: \n",
      "The savefig.frameon rcparam was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
      "  self[key] = other[key]\n"
     ]
    }
   ],
   "source": [
    "# System\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/home/helfrech/Tools/Toolbox/utils')\n",
    "\n",
    "# Maths\n",
    "import numpy as np\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "# ML\n",
    "from regression import PCovR, KPCovR, SparseKPCovR\n",
    "from regression import LR, KRR\n",
    "from kernels import build_kernel, linear_kernel, gaussian_kernel\n",
    "from kernels import center_kernel, center_kernel_fast\n",
    "from kernels import center_kernel_oos, center_kernel_oos_fast\n",
    "from soap import extract_species_pair_groups\n",
    "from errors import MAE\n",
    "\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Utilities\n",
    "import h5py\n",
    "import json\n",
    "import itertools\n",
    "from tqdm.notebook import tqdm\n",
    "import project_utils as utils\n",
    "from tools import load_json\n",
    "\n",
    "# Import COSMO style toolkit\n",
    "import cosmoplot.colorbars as cosmocbars\n",
    "import cosmoplot.utils as cosmoutils\n",
    "import cosmoplot.style as cosmostyle\n",
    "\n",
    "cosmostyle.set_style('article')\n",
    "colorList = cosmostyle.color_cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys.path.append('/scratch/helfrech/Sync/GDrive/Projects/KPCovR/kernel-tutorials')\n",
    "# sys.path.append('/scratch/helfrech/Sync/GDrive/Projects/KPCovR/KernelPCovR/analysis/scripts')\n",
    "# from utilities.sklearn_covr.kpcovr import KernelPCovR as KPCovR2\n",
    "# from utilities.sklearn_covr.pcovr import PCovR as PCovR2\n",
    "# from helpers import l_regr, l_kpcovr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load train and test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SOAP cutoffs\n",
    "with open('../Processed_Data/soap_hyperparameters.json', 'r') as f:\n",
    "    soap_hyperparameters = json.load(f)\n",
    "    \n",
    "cutoffs = soap_hyperparameters['interaction_cutoff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7750 2250\n"
     ]
    }
   ],
   "source": [
    "# Load train and test set indices for Deem\n",
    "idxs_deem_train = np.loadtxt('../Processed_Data/DEEM_10k/train.idxs', dtype=int)\n",
    "idxs_deem_test = np.loadtxt('../Processed_Data/DEEM_10k/test.idxs', dtype=int)\n",
    "\n",
    "# Total number of structures\n",
    "n_deem_train = idxs_deem_train.size\n",
    "n_deem_test = idxs_deem_test.size\n",
    "n_deem = n_deem_train + n_deem_test\n",
    "\n",
    "print(n_deem_train, n_deem_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dummy DEEM cantons\n",
    "cantons_deem = np.ones(n_deem, dtype=int) * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load IZA cantons\n",
    "cantons_iza = np.loadtxt('../Raw_Data/GULP/IZA_226/cantons.txt', usecols=1, dtype=int)\n",
    "RWY = np.nonzero(cantons_iza == 4)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cantons_iza = np.delete(cantons_iza, RWY)\n",
    "n_iza = len(cantons_iza)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112 113\n"
     ]
    }
   ],
   "source": [
    "idxs_iza_train_file = '../Processed_Data/IZA_226/train.idxs' \n",
    "idxs_iza_test_file = '../Processed_Data/IZA_226/test.idxs'\n",
    "\n",
    "# Load IZA train and test set indices\n",
    "try:\n",
    "    idxs_iza_train = np.loadtxt(idxs_iza_train_file, dtype=int)\n",
    "    idxs_iza_test = np.loadtxt(idxs_iza_test_file, dtype=int)\n",
    "    n_iza_train = len(idxs_iza_train)\n",
    "    n_iza_test = len(idxs_iza_test)\n",
    "    \n",
    "    print(n_iza_train, n_iza_test)\n",
    "\n",
    "# Compute indices if they don't exist\n",
    "except IOError:\n",
    "\n",
    "    # Select IZA sample\n",
    "    n_iza_train = n_iza // 2\n",
    "    n_iza_test = n_iza - n_iza_train\n",
    "    idxs_iza = np.arange(0, n_iza)\n",
    "    np.random.shuffle(idxs_iza)\n",
    "\n",
    "    idxs_iza_train = idxs_iza[0:n_iza_train]\n",
    "    idxs_iza_test = idxs_iza[n_iza_train:]\n",
    "    \n",
    "    np.savetxt(idxs_iza_train_file, idxs_iza_train, fmt='%d')\n",
    "    np.savetxt(idxs_iza_test_file, idxs_iza_test, fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build set of \"master\" canton labels\n",
    "cantons_train = {}\n",
    "cantons_test = {}\n",
    "\n",
    "cantons_train[4] = np.concatenate((cantons_iza[idxs_iza_train], cantons_deem[idxs_deem_train]))\n",
    "cantons_test[4] = np.concatenate((cantons_iza[idxs_iza_test], cantons_deem[idxs_deem_test]))\n",
    "\n",
    "cantons_train[2] = np.concatenate((np.ones(len(idxs_iza_train), dtype=int),\n",
    "                                   np.ones(len(idxs_deem_train), dtype=int) * 2))\n",
    "cantons_test[2] = np.concatenate((np.ones(len(idxs_iza_test), dtype=int),\n",
    "                                  np.ones(len(idxs_deem_test), dtype=int) * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = '../Processed_Data/Models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = {}\n",
    "class_names[2] = ['IZA', 'DEEM']\n",
    "class_names[4] = ['IZA1', 'IZA2', 'IZA3', 'DEEM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global model parameters\n",
    "# TODO: or use .get_params()?\n",
    "# TODO: load from optimization?\n",
    "# TODO: should we make sure break_ties=True?\n",
    "svc_kwargs = dict(linear=dict(penalty='l2',\n",
    "                              loss='squared_hinge',\n",
    "                              dual=False,\n",
    "                              multi_class='ovr',\n",
    "                              class_weight=None,\n",
    "                              fit_intercept=True,\n",
    "                              intercept_scaling=1.0,\n",
    "                              tol=1.0E-3,\n",
    "                              C=1.0),\n",
    "                  kernel=dict(kernel='precomputed',\n",
    "                              decision_function_shape='ovr',\n",
    "                              class_weight=None,\n",
    "                              break_ties=False,\n",
    "                              tol=1.0E-3,\n",
    "                              C=10.0))\n",
    "\n",
    "pcovr_kwargs = dict(linear=dict(n_components=None, alpha=0.0, regularization=1.0E-12),\n",
    "                    kernel=dict(n_components=None, alpha=0.0, regularization=1.0E-12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slices for saving KSVC and KPCovR outputs\n",
    "deem_train_slice = slice(n_iza_train, None)\n",
    "deem_test_slice = slice(n_iza_test, None)\n",
    "iza_train_slice = slice(0, n_iza_train)\n",
    "iza_test_slice = slice(0, n_iza_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the kernels or compute if they don't exist\n",
    "for cutoff in cutoffs:\n",
    "    for kernel_type in ('linear', 'gaussian'):\n",
    "        kernel_name = kernel_type.capitalize()\n",
    "        \n",
    "        work_dir = f'{model_dir}/{cutoff}/Kernel_Models/{kernel_name}/KSVC-KPCovR'\n",
    "        \n",
    "        if not os.path.exists(work_dir):\n",
    "            os.makedirs(work_dir)\n",
    "        \n",
    "        # File to store kernels for re-use\n",
    "        kernel_file = f'{work_dir}/structure_kernels.hdf5'\n",
    "        kernel_parameter_file = f'{work_dir}/volumes_mae_parameters.json'\n",
    "\n",
    "        if not os.path.exists(kernel_file):\n",
    "            \n",
    "            # SOAP files (atomwise, FPS'ed features)\n",
    "            deem_file = f'{deem_dir}/{cutoff}/soaps.hdf5'\n",
    "            iza_file = f'{iza_dir}/{cutoff}/soaps.hdf5'\n",
    "\n",
    "            # Assemble the train and test set SOAPs from IZA and DEEM\n",
    "            soaps_train, soaps_test = utils.load_soaps(deem_file, iza_file,\n",
    "                                                       idxs_deem_train, idxs_deem_test,\n",
    "                                                       idxs_iza_train, idxs_iza_test,\n",
    "                                                       idxs_iza_delete=[RWY])\n",
    "\n",
    "            # Compute kernels\n",
    "            # This can be consolidated if doing linear KRR\n",
    "            if kernel_type == 'gaussian':\n",
    "                kernel_parameters = load_json(kernel_parameter_file)\n",
    "                kernel_parameters.pop('sigma')\n",
    "                kernel_parameters.pop('regularization')\n",
    "            else:\n",
    "                kernel_parameters = dict(kernel='linear', zeta=1)\n",
    "            \n",
    "            utils.compute_kernels(soaps_train, soaps_test, **kernel_parameters, kernel_file=kernel_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "deem_name = 'DEEM_10k'\n",
    "iza_name = 'IZA_226onDEEM_10k'\n",
    "deem_dir = f'../Processed_Data/{deem_name}/Data'\n",
    "iza_dir = f'../Processed_Data/{iza_name}/Data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KernelSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be60aa0cba1f4943a754ce1b16401075",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Cutoff', max=2.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Kernel', max=2.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Classes', max=2.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Classes', max=2.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Kernel', max=2.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Classes', max=2.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Classes', max=2.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for cutoff in tqdm(cutoffs, desc='Cutoff', leave=True):\n",
    "    \n",
    "    for kernel_type in tqdm(('linear', 'gaussian'), desc='Kernel', leave=False):\n",
    "        kernel_name = kernel_type.capitalize()\n",
    "        \n",
    "        kernel_dir = f'{model_dir}/{cutoff}/Kernel_Models/{kernel_name}/KSVC-KPCovR'\n",
    "        \n",
    "        # File to store kernels for re-use\n",
    "        kernel_file = f'{kernel_dir}/structure_kernels.hdf5'\n",
    "        \n",
    "        # Load kernels\n",
    "        K_train, K_test, K_test_test = utils.load_kernels(kernel_file)\n",
    "\n",
    "        # Center and scale kernels\n",
    "        K_train, K_test, K_test_test = \\\n",
    "            utils.preprocess_kernels(K_train, K_test=K_test, \n",
    "                                     K_test_test=K_test_test, K_bridge=K_test)\n",
    "        \n",
    "        for n_cantons in tqdm((2, 4), desc='Classes', leave=False):\n",
    "            \n",
    "            # Prepare outputs\n",
    "            output_dir = f'Kernel_Models/{kernel_name}/KSVC-KPCovR/{n_cantons}-Class'\n",
    "            \n",
    "            if not os.path.exists(f'{deem_dir}/{cutoff}/{output_dir}'):\n",
    "                os.makedirs(f'{deem_dir}/{cutoff}/{output_dir}')\n",
    "                \n",
    "            if not os.path.exists(f'{iza_dir}/{cutoff}/{output_dir}'):\n",
    "                os.makedirs(f'{iza_dir}/{cutoff}/{output_dir}')\n",
    "            \n",
    "            svc_df_deem_file = f'{deem_dir}/{cutoff}/{output_dir}/svc_structure_dfs.dat'\n",
    "            svc_df_iza_file = f'{iza_dir}/{cutoff}/{output_dir}/svc_structure_dfs.dat'\n",
    "            \n",
    "            svc_cantons_deem_file = f'{deem_dir}/{cutoff}/{output_dir}/svc_structure_cantons.dat'\n",
    "            svc_cantons_iza_file = f'{iza_dir}/{cutoff}/{output_dir}/svc_structure_cantons.dat'\n",
    "            \n",
    "            parameter_dir = f'{kernel_dir}/{n_cantons}-Class'\n",
    "            svc_parameter_file = f'{parameter_dir}/svc_parameters.json'\n",
    "\n",
    "            # Run KSVC\n",
    "            svc_parameters = svc_kwargs['kernel'].copy() #load_json(svc_parameter_file) ###\n",
    "            df_train, df_test, predicted_cantons_train, predicted_cantons_test = \\\n",
    "                utils.do_svc(K_train, K_test, cantons_train[n_cantons], cantons_test[n_cantons], \n",
    "                             svc_type='kernel', **svc_parameters,\n",
    "                             outputs=['decision_functions', 'predictions'])\n",
    "            \n",
    "            # Save IZA and DEEM KSVC decision functions\n",
    "            utils.split_and_save(df_train, df_test,\n",
    "                           idxs_deem_train, idxs_deem_test,\n",
    "                           deem_train_slice, deem_test_slice,\n",
    "                           output=svc_df_deem_file, output_format='%f',\n",
    "                           hdf5_attrs=None)                           \n",
    "            \n",
    "            utils.split_and_save(df_train, df_test,\n",
    "                                 idxs_iza_train, idxs_iza_test,\n",
    "                                 iza_train_slice, iza_test_slice,\n",
    "                                 output=svc_df_iza_file, output_format='%f',\n",
    "                                 hdf5_attrs=None)\n",
    "            \n",
    "            # Save IZA and DEEM KSVC canton predictions\n",
    "            utils.split_and_save(predicted_cantons_train, predicted_cantons_test,\n",
    "                                 idxs_deem_train, idxs_deem_test,\n",
    "                                 deem_train_slice, deem_test_slice,\n",
    "                                 output=svc_cantons_deem_file, output_format='%d',\n",
    "                                 hdf5_attrs=None)\n",
    "            \n",
    "            utils.split_and_save(predicted_cantons_train, predicted_cantons_test,\n",
    "                                 idxs_iza_train, idxs_iza_test,\n",
    "                                 iza_train_slice, iza_test_slice,\n",
    "                                 output=svc_cantons_iza_file, output_format='%d',\n",
    "                                 hdf5_attrs=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KRR check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76bca02e86c342698e2b9a676894421b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Cutoff', max=2.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Kernel', max=2.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Classes', max=2.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.402407674818527e-07\n",
      "2.563285939083567e-07\n",
      "[0.23737999 0.19256604 0.205351   0.15324587]\n",
      "[0.25570135 0.20392276 0.21818637 0.21883868]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Classes', max=2.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.53750867978601e-09\n",
      "1.7538193820153714e-06\n",
      "[0.00453011 0.0045754  0.00583132 0.00563494]\n",
      "[1.2519002  1.1003435  1.3837016  2.18657991]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4477601e7544e78852f2e743ae94d2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Kernel', max=2.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6241a89ab79c419e96fbb6fdf161f874",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Classes', max=2.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-4363992c8308>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m             dfp_train, dfp_test = utils.regression_check(K_train, K_test, \n\u001b[1;32m     33\u001b[0m                                                          \u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                                                          regression_type='kernel')\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfp_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/helfrech/Sync/GDrive/Projects/Zeolites_IZA-DEEM2/Scripts/project_utils.py\u001b[0m in \u001b[0;36mregression_check\u001b[0;34m(train_data, test_data, train_target, test_target, regression_type)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0mregressor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregression_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregularization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0E-12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m     \u001b[0mregressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m     \u001b[0mpredicted_train_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0mpredicted_test_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Tools/Toolbox/utils/regression.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, K, Y)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;31m# Solve the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstsq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcond\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcond\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mlstsq\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/ENVIRONMENTS/ZEOLITES/lib/python3.6/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36mlstsq\u001b[0;34m(a, b, rcond)\u001b[0m\n\u001b[1;32m   2266\u001b[0m         \u001b[0;31m# lapack can't handle n_rhs = 0 - so allocate the array one larger in that axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2267\u001b[0m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_rhs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2268\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgufunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2269\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2270\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for cutoff in tqdm(cutoffs, desc='Cutoff', leave=True):\n",
    "    \n",
    "    for kernel_type in tqdm(('linear', 'gaussian'), desc='Kernel', leave=False):\n",
    "        kernel_name = kernel_type.capitalize()\n",
    "        \n",
    "        kernel_dir = f'{model_dir}/{cutoff}/Kernel_Models/{kernel_name}/KSVC-KPCovR'\n",
    "        \n",
    "        # Load kernels\n",
    "        kernel_file = f'{kernel_dir}/structure_kernels.hdf5'\n",
    "        K_train, K_test, K_test_test = utils.load_kernels(kernel_file)\n",
    "\n",
    "        # Center and scale kernels\n",
    "        K_train, K_test, K_test_test = \\\n",
    "            utils.preprocess_kernels(K_train, K_test=K_test, \n",
    "                                     K_test_test=K_test_test, K_bridge=K_test)\n",
    "        \n",
    "        for n_cantons in tqdm((2, 4), desc='Classes', leave=False):\n",
    "            \n",
    "            # Load decision functions\n",
    "            input_dir = f'Kernel_Models/{kernel_name}/KSVC-KPCovR/{n_cantons}-Class'\n",
    "            svc_df_deem_file = f'{deem_dir}/{cutoff}/{input_dir}/svc_structure_dfs.dat'\n",
    "            svc_df_iza_file = f'{iza_dir}/{cutoff}/{input_dir}/svc_structure_dfs.dat'\n",
    "            \n",
    "            df_train, df_test = utils.load_data(svc_df_deem_file, svc_df_iza_file,\n",
    "                                                idxs_deem_train, idxs_deem_test,\n",
    "                                                idxs_iza_train, idxs_iza_test)\n",
    "            \n",
    "            # Center and scale the decision functions\n",
    "            df_train, df_test, df_center, df_scale = \\\n",
    "                utils.preprocess_data(df_train, df_test)\n",
    "\n",
    "            # Check that KRR can reproduce the decision functions\n",
    "            dfp_train, dfp_test = utils.regression_check(K_train, K_test, \n",
    "                                                         df_train, df_test, \n",
    "                                                         regression_type='kernel')\n",
    "            \n",
    "            print(MAE(dfp_train, df_train))\n",
    "            print(MAE(dfp_test, df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KPCovR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "673e022a450e4a65ab01ca5a0526cf31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Cutoff', max=2.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Kernel', max=2.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Classes', max=2.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Classes', max=2.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Kernel', max=2.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Classes', max=2.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Classes', max=2.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for cutoff in tqdm(cutoffs, desc='Cutoff', leave=True):\n",
    "    \n",
    "    for kernel_type in tqdm(('linear', 'gaussian'), desc='Kernel', leave=False):\n",
    "        kernel_name = kernel_type.capitalize()\n",
    "        \n",
    "        kernel_dir = f'{model_dir}/{cutoff}/Kernel_Models/{kernel_name}/KSVC-KPCovR'\n",
    "        \n",
    "        # Load kernels\n",
    "        kernel_file = f'{kernel_dir}/structure_kernels.hdf5'\n",
    "        K_train, K_test, K_test_test = utils.load_kernels(kernel_file)\n",
    "\n",
    "        # Center and scale kernels\n",
    "        K_train, K_test, K_test_test = \\\n",
    "            utils.preprocess_kernels(K_train, K_test=K_test, \n",
    "                                     K_test_test=K_test_test, K_bridge=K_test)\n",
    "        \n",
    "        for n_cantons in tqdm((2, 4), desc='Classes', leave=False):\n",
    "            \n",
    "            # Prepare outputs\n",
    "            output_dir = f'Kernel_Models/{kernel_name}/KSVC-KPCovR/{n_cantons}-Class'\n",
    "            \n",
    "            svc_df_deem_file = f'{deem_dir}/{cutoff}/{output_dir}/svc_structure_dfs.dat'\n",
    "            svc_df_iza_file = f'{iza_dir}/{cutoff}/{output_dir}/svc_structure_dfs.dat'\n",
    "            \n",
    "            pcovr_projection_deem_file = f'{deem_dir}/{cutoff}/{output_dir}/pcovr_structures.hdf5' \n",
    "            pcovr_projection_iza_file = f'{iza_dir}/{cutoff}/{output_dir}/pcovr_structures.hdf5'\n",
    "            \n",
    "            pcovr_df_deem_file = f'{deem_dir}/{cutoff}/{output_dir}/pcovr_structure_dfs.dat'\n",
    "            pcovr_df_iza_file = f'{iza_dir}/{cutoff}/{output_dir}/pcovr_structure_dfs.dat'\n",
    "            \n",
    "            pcovr_cantons_deem_file = f'{deem_dir}/{cutoff}/{output_dir}/pcovr_structure_cantons.dat'\n",
    "            pcovr_cantons_iza_file = f'{iza_dir}/{cutoff}/{output_dir}/pcovr_structure_cantons.dat'\n",
    "            \n",
    "            parameter_dir = f'{kernel_dir}/{n_cantons}-Class'\n",
    "            pcovr_parameter_file = f'{parameter_dir}/pcovr_parameters.json'\n",
    "            svc_parameter_file = f'{parameter_dir}/svc_parameters.json'\n",
    "            \n",
    "            df_train, df_test = utils.load_data(svc_df_deem_file, svc_df_iza_file,\n",
    "                                                idxs_deem_train, idxs_deem_test,\n",
    "                                                idxs_iza_train, idxs_iza_test)\n",
    "            \n",
    "            # Center and scale the decision functions\n",
    "            df_train, df_test, df_center, df_scale = \\\n",
    "                utils.preprocess_data(df_train, df_test)\n",
    "            \n",
    "            # Run KPCovR\n",
    "            pcovr_parameters = pcovr_kwargs['kernel'].copy() #load_json(pcovr_parameter_file) ###\n",
    "            svc_parameters = svc_kwargs['kernel'].copy() #load_json(svc_parameter_file) ###\n",
    "            T_train, T_test, dfp_train, dfp_test = \\\n",
    "                utils.do_pcovr(K_train, K_test, df_train, df_test, \n",
    "                               pcovr_type='kernel', **pcovr_parameters)\n",
    "                      \n",
    "            # Post process the KPCovR decision functions\n",
    "            # (i.e., turn them back into canton predictions)\n",
    "            predicted_cantons_train, predicted_cantons_test = \\\n",
    "                utils.postprocess_decision_functions(dfp_train, dfp_test, df_center, df_scale,\n",
    "                                                     df_type=svc_parameters['decision_function_shape'],\n",
    "                                                     n_classes=n_cantons)\n",
    "            \n",
    "            # Save IZA and DEEM KPCovR projections\n",
    "            utils.split_and_save(T_train, T_test,\n",
    "                                 idxs_deem_train, idxs_deem_test,\n",
    "                                 deem_train_slice, deem_test_slice,\n",
    "                                 output=pcovr_projection_deem_file, output_format='%f',\n",
    "                                 hdf5_attrs=pcovr_parameters)\n",
    "            \n",
    "            utils.split_and_save(T_train, T_test,\n",
    "                                 idxs_iza_train, idxs_iza_test,\n",
    "                                 iza_train_slice, iza_test_slice,\n",
    "                                 output=pcovr_projection_iza_file, output_format='%f',\n",
    "                                 hdf5_attrs=pcovr_parameters)            \n",
    "            \n",
    "            # Save IZA and DEEM KPCovR decision functions\n",
    "            utils.split_and_save(dfp_train, dfp_test,\n",
    "                                 idxs_deem_train, idxs_deem_test,\n",
    "                                 deem_train_slice, deem_test_slice,\n",
    "                                 output=pcovr_df_deem_file, output_format='%f',\n",
    "                                 hdf5_attrs=None)\n",
    "            \n",
    "            utils.split_and_save(dfp_train, dfp_test,\n",
    "                                 idxs_iza_train, idxs_iza_test,\n",
    "                                 iza_train_slice, iza_test_slice,\n",
    "                                 output=pcovr_df_iza_file, output_format='%f', \n",
    "                                 hdf5_attrs=None)\n",
    "            \n",
    "            # Save IZA and DEEM KPCovR canton predictions\n",
    "            utils.split_and_save(predicted_cantons_train, predicted_cantons_test,\n",
    "                                 idxs_deem_train, idxs_deem_test,\n",
    "                                 deem_train_slice, deem_test_slice,\n",
    "                                 output=pcovr_cantons_deem_file, output_format='%d',\n",
    "                                 hdf5_attrs=None)\n",
    "            \n",
    "            utils.split_and_save(predicted_cantons_train, predicted_cantons_test,\n",
    "                                 idxs_iza_train, idxs_iza_test,\n",
    "                                 iza_train_slice, iza_test_slice,\n",
    "                                 output=pcovr_cantons_iza_file, output_format='%d',\n",
    "                                 hdf5_attrs=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear model setup\n",
    "n_species = 2\n",
    "group_names = {'power': ['OO', 'OSi', 'SiSi', \n",
    "                         'OO+OSi', 'OO+SiSi', 'OSi+SiSi',\n",
    "                         'OO+OSi+SiSi'], \n",
    "               'radial': ['O', 'Si', 'O+Si']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "deem_name = 'DEEM_10k'\n",
    "iza_name = 'IZA_226'\n",
    "deem_dir = f'../Processed_Data/{deem_name}/Data'\n",
    "iza_dir = f'../Processed_Data/{iza_name}/Data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97797a0fbf984b5990b81c2128a804bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Cutoff', max=2.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Spectrum', max=2.0, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Species', max=7.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Classes', max=2.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Classes', max=2.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Classes', max=2.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Classes', max=2.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Classes', max=2.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Classes', max=2.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Classes', max=2.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Species', max=3.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Classes', max=2.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Classes', max=2.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Classes', max=2.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Spectrum', max=2.0, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Species', max=7.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Classes', max=2.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Classes', max=2.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Classes', max=2.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Classes', max=2.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Classes', max=2.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Classes', max=2.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Classes', max=2.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Species', max=3.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Classes', max=2.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Classes', max=2.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Classes', max=2.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for cutoff in tqdm(cutoffs, desc='Cutoff', leave=True):\n",
    "    linear_dir = f'{model_dir}/{cutoff}/Linear_Models/LSVC-LPCovR'\n",
    "    \n",
    "    for spectrum_type in tqdm(('power', 'radial'), desc='Spectrum', leave=False):\n",
    "        spectrum_name = spectrum_type.capitalize()\n",
    "        \n",
    "        # Load SOAPs\n",
    "        deem_file = f'{deem_dir}/{cutoff}/soaps_{spectrum_type}_full_avg_nonorm.hdf5'\n",
    "        iza_file = f'{iza_dir}/{cutoff}/soaps_{spectrum_type}_full_avg_nonorm.hdf5'\n",
    "        \n",
    "        soaps_train, soaps_test = utils.load_soaps(deem_file, iza_file,\n",
    "                                                   idxs_deem_train, idxs_deem_test,\n",
    "                                                   idxs_iza_train, idxs_iza_test,\n",
    "                                                   idxs_iza_delete=[RWY],\n",
    "                                                   train_test_concatenate=True)\n",
    "\n",
    "        # Scale the SOAPs so they are of a 'usable' magnitude for the SVC\n",
    "        soaps_train, soaps_test = utils.preprocess_soaps(soaps_train, soaps_test)\n",
    "        \n",
    "        n_features = soaps_train.shape[1]\n",
    "        feature_groups = extract_species_pair_groups(n_features, n_species, \n",
    "                                                     spectrum_type=spectrum_type,\n",
    "                                                     combinations=True)\n",
    "\n",
    "        for species_pairing, feature_idxs in zip(tqdm(group_names[spectrum_type], \n",
    "                                                      desc='Species', leave=False),\n",
    "                                                 feature_groups):\n",
    "            \n",
    "            for n_cantons in tqdm((2, 4), desc='Classes', leave=False):\n",
    "                                \n",
    "                # Prepare outputs\n",
    "                output_dir = f'Linear_Models/LSVC-LPCovR/{n_cantons}-Class/{spectrum_name}/{species_pairing}'\n",
    "                \n",
    "                if not os.path.exists(f'{deem_dir}/{cutoff}/{output_dir}'):\n",
    "                    os.makedirs(f'{deem_dir}/{cutoff}/{output_dir}')\n",
    "                    \n",
    "                if not os.path.exists(f'{iza_dir}/{cutoff}/{output_dir}'):\n",
    "                    os.makedirs(f'{iza_dir}/{cutoff}/{output_dir}')\n",
    "                \n",
    "                svc_df_deem_file = f'{deem_dir}/{cutoff}/{output_dir}/svc_structure_dfs.dat'\n",
    "                svc_df_iza_file = f'{iza_dir}/{cutoff}/{output_dir}/svc_structure_dfs.dat'\n",
    "\n",
    "                svc_cantons_deem_file = f'{deem_dir}/{cutoff}/{output_dir}/svc_structure_cantons.dat'\n",
    "                svc_cantons_iza_file = f'{iza_dir}/{cutoff}/{output_dir}/svc_structure_cantons.dat'\n",
    "                                \n",
    "                parameter_dir = f'{linear_dir}/{n_cantons}-Class/{spectrum_name}/{species_pairing}'\n",
    "                svc_parameter_file = f'{parameter_dir}/svc_parameters.json'\n",
    "                \n",
    "                svc_weights_file = f'{parameter_dir}/svc_weights.dat'\n",
    "\n",
    "                # Run LSVC\n",
    "                svc_parameters = svc_kwargs['linear'].copy() #load_json(svc_parameter_file) ###\n",
    "                df_train, df_test, predicted_cantons_train, predicted_cantons_test, weights = \\\n",
    "                    utils.do_svc(soaps_train[:, feature_idxs], soaps_test[:, feature_idxs], \n",
    "                                 cantons_train[n_cantons], cantons_test[n_cantons], \n",
    "                                 svc_type='linear', **svc_parameters,\n",
    "                                 outputs=['decision_functions', 'predictions', 'weights'])\n",
    "\n",
    "                # Save IZA and DEEM LSVC decision functions\n",
    "                utils.split_and_save(df_train, df_test,\n",
    "                                     idxs_deem_train, idxs_deem_test,\n",
    "                                     deem_train_slice, deem_test_slice,\n",
    "                                     output=svc_df_deem_file, output_format='%f',\n",
    "                                     hdf5_attrs=None)\n",
    "                \n",
    "                utils.split_and_save(df_train, df_test,\n",
    "                                     idxs_iza_train, idxs_iza_test,\n",
    "                                     iza_train_slice, iza_test_slice,\n",
    "                                     output=svc_df_iza_file, output_format='%f',\n",
    "                                     hdf5_attrs=None)\n",
    "\n",
    "                # Save IZA and DEEM LSVC canton predictions\n",
    "                utils.split_and_save(predicted_cantons_train, predicted_cantons_test,\n",
    "                                     idxs_deem_train, idxs_deem_test,\n",
    "                                     deem_train_slice, deem_test_slice,\n",
    "                                     output=svc_cantons_deem_file, output_format='%d',\n",
    "                                     hdf5_attrs=None)\n",
    "                \n",
    "                utils.split_and_save(predicted_cantons_train, predicted_cantons_test,\n",
    "                                     idxs_iza_train, idxs_iza_test,\n",
    "                                     iza_train_slice, iza_test_slice,\n",
    "                                     output=svc_cantons_iza_file, output_format='%d',\n",
    "                                     hdf5_attrs=None)\n",
    "                \n",
    "                # Save weights\n",
    "                np.savetxt(svc_weights_file, weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cutoff in tqdm(cutoffs, desc='Cutoff', leave=True):\n",
    "    \n",
    "    for spectrum_type in tqdm(('power', 'radial'), desc='Spectrum', leave=False):\n",
    "        spectrum_name = spectrum_type.capitalize()\n",
    "        \n",
    "        # Load SOAPs\n",
    "        deem_file = f'{deem_dir}/{cutoff}/soaps_{spectrum_type}_full_avg_nonorm.hdf5'\n",
    "        iza_file = f'{iza_dir}/{cutoff}/soaps_{spectrum_type}_full_avg_nonorm.hdf5'\n",
    "\n",
    "        soaps_train, soaps_test = utils.load_soaps(deem_file, iza_file,\n",
    "                                                   idxs_deem_train, idxs_deem_test,\n",
    "                                                   idxs_iza_train, idxs_iza_test,\n",
    "                                                   idxs_iza_delete=[RWY],\n",
    "                                                   train_test_concatenate=True)\n",
    "        \n",
    "        n_features = soaps_train.shape[1]\n",
    "        feature_groups = extract_species_pair_groups(n_features, n_species, \n",
    "                                                     spectrum_type=spectrum_type, \n",
    "                                                     combinations=True)\n",
    "        \n",
    "        for species_pairing, feature_idxs in zip(tqdm(group_names[spectrum_type], \n",
    "                                                      desc='Species', leave=False),\n",
    "                                                 feature_groups):\n",
    "            \n",
    "            x_train = soaps_train[:, feature_idxs]\n",
    "            x_test = soaps_test[:, feature_idxs]\n",
    "\n",
    "            # Preprocess the SOAPs like the decision functions\n",
    "            # (i.e., center and scale) for the regression.\n",
    "            x_train, x_test, x_center, x_scale = \\\n",
    "                utils.preprocess_data(x_train, x_test)\n",
    "            \n",
    "            for n_cantons in tqdm((2, 4), desc='Classes', leave=False):\n",
    "                \n",
    "                # Load decision functions\n",
    "                input_dir = f'Linear_Models/LSVC-LPCovR/{n_cantons}-Class/{spectrum_name}/{species_pairing}'\n",
    "                svc_df_deem_file = f'{deem_dir}/{cutoff}/{input_dir}/svc_structure_dfs.dat'\n",
    "                svc_df_iza_file = f'{iza_dir}/{cutoff}/{input_dir}/svc_structure_dfs.dat'\n",
    "\n",
    "                df_train, df_test = utils.load_data(svc_df_deem_file, svc_df_iza_file,\n",
    "                                                    idxs_deem_train, idxs_deem_test,\n",
    "                                                    idxs_iza_train, idxs_iza_test)\n",
    "                \n",
    "                # Center and scale the decision functions\n",
    "                df_train, df_test, df_center, df_scale = \\\n",
    "                    utils.preprocess_data(df_train, df_test)\n",
    "                \n",
    "                # Check that LR can reproduce the decision functions\n",
    "                dfp_train, dfp_test = utils.regression_check(x_train, x_test, \n",
    "                                                             df_train, df_test, \n",
    "                                                             regression_type='linear')\n",
    "                \n",
    "                print(MAE(dfp_train, df_train))\n",
    "                print(MAE(dfp_test, df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCovR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04992bf486224b08b72830fc808070bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Cutoff', max=2.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Spectrum', max=2.0, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Species', max=7.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Classes', max=2.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Classes', max=2.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Classes', max=2.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Classes', max=2.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Classes', max=2.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Classes', max=2.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Classes', max=2.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Species', max=3.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Classes', max=2.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Classes', max=2.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Classes', max=2.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Spectrum', max=2.0, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Species', max=7.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Classes', max=2.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Classes', max=2.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Classes', max=2.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Classes', max=2.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Classes', max=2.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Classes', max=2.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Classes', max=2.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Species', max=3.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Classes', max=2.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Classes', max=2.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Classes', max=2.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for cutoff in tqdm(cutoffs, desc='Cutoff', leave=True):\n",
    "    linear_dir = f'{model_dir}/{cutoff}/Linear_Models/LSVC-LPCovR'\n",
    "    \n",
    "    for spectrum_type in tqdm(('power', 'radial'), desc='Spectrum', leave=False):\n",
    "        spectrum_name = spectrum_type.capitalize()\n",
    "        \n",
    "        # Load SOAPs\n",
    "        deem_file = f'{deem_dir}/{cutoff}/soaps_{spectrum_type}_full_avg_nonorm.hdf5'\n",
    "        iza_file = f'{iza_dir}/{cutoff}/soaps_{spectrum_type}_full_avg_nonorm.hdf5'\n",
    "\n",
    "        soaps_train, soaps_test = utils.load_soaps(deem_file, iza_file,\n",
    "                                                   idxs_deem_train, idxs_deem_test,\n",
    "                                                   idxs_iza_train, idxs_iza_test,\n",
    "                                                   idxs_iza_delete=[RWY],\n",
    "                                                   train_test_concatenate=True)\n",
    "        \n",
    "        # Scale the SOAPs so they are of a 'usable' magnitude for the SVC\n",
    "        #soaps_train, soaps_test = utils.preprocess_soaps(soaps_train, soaps_test)\n",
    "        \n",
    "        n_features = soaps_train.shape[1]\n",
    "        feature_groups = extract_species_pair_groups(n_features, n_species, \n",
    "                                                     spectrum_type=spectrum_type,\n",
    "                                                     combinations=True)\n",
    "        \n",
    "        for species_pairing, feature_idxs in zip(tqdm(group_names[spectrum_type], \n",
    "                                                      desc='Species', leave=False),\n",
    "                                                 feature_groups):\n",
    "            \n",
    "            x_train = soaps_train[:, feature_idxs]\n",
    "            x_test = soaps_test[:, feature_idxs]\n",
    "\n",
    "            # Preprocess the SOAPs like the decision functions\n",
    "            # (i.e., center and scale) for the regression.\n",
    "            x_train, x_test, x_center, x_scale = \\\n",
    "                utils.preprocess_data(x_train, x_test)\n",
    "            \n",
    "            for n_cantons in tqdm((2, 4), desc='Classes', leave=False):\n",
    "                \n",
    "                # Prepare outputs\n",
    "                output_dir = f'Linear_Models/LSVC-LPCovR/{n_cantons}-Class/{spectrum_name}/{species_pairing}'\n",
    "                \n",
    "                svc_df_deem_file = f'{deem_dir}/{cutoff}/{output_dir}/svc_structure_dfs.dat'\n",
    "                svc_df_iza_file = f'{iza_dir}/{cutoff}/{output_dir}/svc_structure_dfs.dat'\n",
    "                \n",
    "                pcovr_projection_deem_file = f'{deem_dir}/{cutoff}/{output_dir}/pcovr_structures.hdf5'\n",
    "                pcovr_projection_iza_file = f'{iza_dir}/{cutoff}/{output_dir}/pcovr_structures.hdf5'\n",
    "                \n",
    "                pcovr_df_deem_file = f'{deem_dir}/{cutoff}/{output_dir}/pcovr_structure_dfs.dat'\n",
    "                pcovr_df_iza_file = f'{iza_dir}/{cutoff}/{output_dir}/pcovr_structure_dfs.dat'\n",
    "                \n",
    "                pcovr_cantons_deem_file = f'{deem_dir}/{cutoff}/{output_dir}/pcovr_structure_cantons.dat'\n",
    "                pcovr_cantons_iza_file = f'{iza_dir}/{cutoff}/{output_dir}/pcovr_structure_cantons.dat'\n",
    "                \n",
    "                parameter_dir = f'{linear_dir}/{n_cantons}-Class/{spectrum_name}/{species_pairing}'\n",
    "                pcovr_parameter_file = f'{parameter_dir}/pcovr_parameters.json'\n",
    "                \n",
    "                df_train, df_test = utils.load_data(svc_df_deem_file, svc_df_iza_file,\n",
    "                                                    idxs_deem_train, idxs_deem_test,\n",
    "                                                    idxs_iza_train, idxs_iza_test)\n",
    "            \n",
    "                # Center and scale the decision functions\n",
    "                df_train, df_test, df_center, df_scale = \\\n",
    "                    utils.preprocess_data(df_train, df_test)\n",
    "                \n",
    "                # Run PCovR\n",
    "                pcovr_parameters = svc_kwargs['linear'].copy() #load_json(pcovr_parameter_file) ###\n",
    "                T_train, T_test, dfp_train, dfp_test = \\\n",
    "                    utils.do_pcovr(x_train, x_test, df_train, df_test, \n",
    "                                   pcovr_type='linear', **pcovr_parameters)\n",
    "\n",
    "                # Post process the PCovR decision functions\n",
    "                # (i.e., turn them back into canton predictions)\n",
    "                predicted_cantons_train, predicted_cantons_test = \\\n",
    "                    utils.postprocess_decision_functions(dfp_train, dfp_test, df_center, df_scale,\n",
    "                                                         df_type=svc_parameters['multi_class'],\n",
    "                                                         n_classes=n_cantons)\n",
    "                \n",
    "                # Save IZA and DEEM PCovR projections\n",
    "                utils.split_and_save(T_train, T_test,\n",
    "                                     idxs_deem_train, idxs_deem_test,\n",
    "                                     deem_train_slice, deem_test_slice,\n",
    "                                     output=pcovr_projection_deem_file, output_format='%f',\n",
    "                                     hdf5_attrs=pcovr_parameters)\n",
    "                \n",
    "                utils.split_and_save(T_train, T_test,\n",
    "                                     idxs_iza_train, idxs_iza_test,\n",
    "                                     iza_train_slice, iza_test_slice,\n",
    "                                     output=pcovr_projection_iza_file, output_format='%f',\n",
    "                                     hdf5_attrs=pcovr_parameters)\n",
    "\n",
    "                # Save IZA and DEEM PCovR decision functions\n",
    "                utils.split_and_save(dfp_train, dfp_test,\n",
    "                                     idxs_deem_train, idxs_deem_test,\n",
    "                                     deem_train_slice, deem_test_slice,\n",
    "                                     output=pcovr_df_deem_file, output_format='%f',\n",
    "                                     hdf5_attrs=None)\n",
    "                \n",
    "                utils.split_and_save(dfp_train, dfp_test,\n",
    "                                     idxs_iza_train, idxs_iza_test,\n",
    "                                     iza_train_slice, iza_test_slice,\n",
    "                                     output=pcovr_df_iza_file, output_format='%f',\n",
    "                                     hdf5_attrs=None)\n",
    "\n",
    "                # Save IZA and DEEM PCovR canton predictions\n",
    "                utils.split_and_save(predicted_cantons_train, predicted_cantons_test,\n",
    "                                     idxs_deem_train, idxs_deem_test,\n",
    "                                     deem_train_slice, deem_test_slice,\n",
    "                                     output=pcovr_cantons_deem_file, output_format='%d',\n",
    "                                     hdf5_attrs=None)\n",
    "                \n",
    "                utils.split_and_save(predicted_cantons_train, predicted_cantons_test,\n",
    "                                     idxs_iza_train, idxs_iza_test,\n",
    "                                     iza_train_slice, iza_test_slice,\n",
    "                                     output=pcovr_cantons_iza_file, output_format='%d',\n",
    "                                     hdf5_attrs=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for cutoff in cutoffs:\n",
    "    \n",
    "    model_dir = f'../Processed_Data/Models/{cutoff}'\n",
    "    with open(f'{model_dir}/ksvc_parameters.json', 'r') as f:\n",
    "        model_dict = json.load(f)\n",
    "        \n",
    "    if C_override is not None:\n",
    "        C = C_override\n",
    "    else:\n",
    "        C = model_dict['C']\n",
    "    \n",
    "    # TODO: if using LogisticRegression, need to optimize with LogisticRegression, but re-use C for now\n",
    "    # NOTE: no ovo option for LogisticRegression\n",
    "    # NOTE: logistic regression seems to want to predict everything as DEEM, moreso than SVM\n",
    "    logr = LogisticRegression(penalty='l2', dual=False, C=C, \n",
    "                              fit_intercept=True, solver='saga',\n",
    "                              multi_class='auto', max_iter=1000, tol=1.0E-3)\n",
    "    \n",
    "    logr.fit(soaps_train[cutoff], cantons_train)\n",
    "    \n",
    "    df_train = logr.decision_function(soaps_train[cutoff])\n",
    "    df_test = logr.decision_function(soaps_test[cutoff])\n",
    "    \n",
    "    predicted_cantons_train = logr.predict(soaps_train[cutoff])\n",
    "    predicted_cantons_test = logr.predict(soaps_test[cutoff])\n",
    "    \n",
    "    probabilities_train = logr.predict_proba(soaps_train[cutoff])\n",
    "    probabilities_test = logr.predict_proba(soaps_test[cutoff])\n",
    "    \n",
    "    # Save decision functions\n",
    "    if n_classes == 2:\n",
    "        df_deem = np.zeros(n_deem)\n",
    "        df_iza = np.zeros(n_iza)\n",
    "    else:\n",
    "        n_df = n_classes\n",
    "            \n",
    "        df_deem = np.zeros((n_deem, n_df))\n",
    "        df_iza = np.zeros((n_iza, n_df))\n",
    "    \n",
    "    df_deem[idxs_deem_train] = df_train[n_iza_train:]\n",
    "    df_deem[idxs_deem_test] = df_test[n_iza_test:]\n",
    "    np.savetxt(f'../Processed_Data/DEEM_10k/Data/{cutoff}/logr_structure_dfs.dat', df_deem)\n",
    "    \n",
    "    df_iza[idxs_iza_train] = df_train[0:n_iza_train]\n",
    "    df_iza[idxs_iza_test] = df_test[0:n_iza_test]\n",
    "    np.savetxt(f'../Processed_Data/IZA_226onDEEM_10k/Data/{cutoff}/logr_structure_dfs.dat', df_iza)\n",
    "    \n",
    "    # Save LogR class predictions\n",
    "    predicted_cantons_deem = np.zeros(n_deem)\n",
    "    predicted_cantons_deem[idxs_deem_train] = predicted_cantons_train[n_iza_train:]\n",
    "    predicted_cantons_deem[idxs_deem_test] = predicted_cantons_test[n_iza_test:]\n",
    "    np.savetxt(f'../Processed_Data/DEEM_10k/Data/{cutoff}/logr_structure_cantons.dat',\n",
    "               predicted_cantons_deem, fmt='%d')\n",
    "    \n",
    "    predicted_cantons_iza = np.zeros(n_iza)\n",
    "    predicted_cantons_iza[idxs_iza_train] = predicted_cantons_train[0:n_iza_train]\n",
    "    predicted_cantons_iza[idxs_iza_test] = predicted_cantons_test[0:n_iza_test]\n",
    "    np.savetxt(f'../Processed_Data/IZA_226onDEEM_10k/Data/{cutoff}/logr_structure_cantons.dat', \n",
    "               predicted_cantons_iza, fmt='%d')\n",
    "    \n",
    "    # Save LogR probabilities\n",
    "    probabilities_deem = np.zeros((n_deem, n_classes))\n",
    "    probabilities_deem[idxs_deem_train] = probabilities_train[n_iza_train:]\n",
    "    probabilities_deem[idxs_deem_test] = probabilities_test[n_iza_test:]\n",
    "    np.savetxt(f'../Processed_Data/DEEM_10k/Data/{cutoff}/logr_structure_probabilities.dat',\n",
    "               predicted_cantons_deem, fmt='%d')\n",
    "    \n",
    "    probabilities_iza = np.zeros((n_iza, n_classes))\n",
    "    probabilities_iza[idxs_iza_train] = probabilities_train[0:n_iza_train]\n",
    "    probabilities_iza[idxs_iza_test] = probabilities_test[0:n_iza_test]\n",
    "    np.savetxt(f'../Processed_Data/IZA_226onDEEM_10k/Data/{cutoff}/logr_structure_probabilities.dat', \n",
    "               predicted_cantons_iza, fmt='%d')\n",
    "    \n",
    "#########\n",
    "    print(logr.score(soaps_train[cutoff], cantons_train))\n",
    "    print(logr.score(soaps_test[cutoff], cantons_test))\n",
    "    print(logr.coef_)\n",
    "    w = reshape_soaps(logr.coef_, 3, 12, 9)\n",
    "    density = compute_soap_density(12, 9, cutoff, w,\n",
    "                                   np.linspace(0, cutoff, 50),\n",
    "                                   np.linspace(-1, 1, 50),\n",
    "                                   chunk_size_r=10, chunk_size_p=10)\n",
    "#########"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "logr.n_iter_"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(probabilities_deem)\n",
    "print(probabilities_iza)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(np.amax(probabilities_deem, axis=1))\n",
    "print(np.amax(probabilities_iza, axis=1))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(np.amax(probabilities_deem))\n",
    "print(np.amax(probabilities_iza))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.hist(probabilities_deem[:, 3], bins=50, density=True, alpha=0.5)\n",
    "plt.hist(probabilities_iza[:, 3], bins=50, density=True, alpha=0.5)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "353.2px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
