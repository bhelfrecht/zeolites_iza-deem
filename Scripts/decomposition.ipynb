{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/home/helfrech/Tools/Toolbox/utils')\n",
    "\n",
    "# Maths\n",
    "import numpy as np\n",
    "\n",
    "# ML\n",
    "from decomposition import IterativeSparseKPCA, KPCA\n",
    "from kernels import build_kernel, linear_kernel, gaussian_kernel\n",
    "\n",
    "# Utilities\n",
    "import h5py\n",
    "import json\n",
    "from project_utils import load_structures_from_hdf5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SOAP cutoffs\n",
    "with open('../Processeed_Data/soap_hyperparameters.json', 'r') as f:\n",
    "    soap_hyperparameters = json.load(f)\n",
    "    \n",
    "cutoffs = soap_hyperparameters['interaction_cutoff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "representative_soaps = {}\n",
    "\n",
    "for cutoff in cutoffs:\n",
    "    work_dir = '../Processed_Data/DEEM_10k/Data/{cutoff}'\n",
    "    n_Si = np.loadtxt('{work_dir}/n_Si.dat', dtype=int)\n",
    "    split_idxs = np.cumsum(n_Si)[0:-1]\n",
    "    representative_idxs = np.loadtxt('{work_dir}/FPS_representatives.idxs', dtype=int)\n",
    "    soaps_file = '{work_dir}/soaps.hdf5'\n",
    "    representative_soaps['{cutoff}'] = build_representatives_from_hdf5(soaps_file, representative_idxs, split_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_kpca = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_iskpca(iskpca_environments_file, iskpca_structures_file, kernel_file,\n",
    "                     representative_soaps, work_dir='.')\n",
    "    \n",
    "    # Read SOAPs\n",
    "    soaps = load_structures_from_hdf5('{work_dir}/soaps.hdf5')\n",
    "    \n",
    "   # Unpickle the kernel parameters\n",
    "    with open(kernel_file, 'r') as f:\n",
    "        kernel_dict = json.load(f)\n",
    "    \n",
    "    kernel_type = kernel_dict['kernel_type']\n",
    "    kernel_parameters = kernel_dict['kernel_parameters']\n",
    "    \n",
    "    # Unpickle the reference DEEM_10k models\n",
    "    # TODO: build objects and set __dict__\n",
    "    with open(iskpca_environments_file, 'r') as f:\n",
    "        iskpca_environments = json.load(f)\n",
    "        \n",
    "    with open(iskpca_structures_file, 'r') as f:\n",
    "        iskpca_structures = json.load(f)\n",
    "\n",
    "    # Initialize the KPCA output\n",
    "    g = h5py.File('{work_dir}/kpca_environments.hdf5', 'w')\n",
    "    h = h5py.File('{work_dir}/kpca_structures.hdf5', 'w')\n",
    "    \n",
    "    # Save kernel parameters to the HDF5 files\n",
    "        for file_obj in (g, h):\n",
    "            file_obj.attrs['kernel_type'] = kernel_type\n",
    "            file_obj.attrs['n_kpca'] = n_kpca\n",
    "            for key, value in kernel_parameters.items():\n",
    "                file_obj.attrs[key] = value        \n",
    "    \n",
    "    # Transform the data and save\n",
    "    for sdx, soap in enumerate(soaps):\n",
    "        KNMi = build_kernel(soap, representative_soaps,\n",
    "                          kernel=kernel_type, **kernel_parameters)\n",
    "        kpcai_environments = iskpca_environments.transform(KNMi)\n",
    "        kpcai_structures = iskpca_structures.transform(np.mean(KNMi, axis=0))\n",
    "        g.create_dataset('{sdx}'.format(sdx), data=kpcai_environments, track_order=True)\n",
    "        h.create_dataset('{sdx}'.format(sdx), data=kpcai_structures, track_order=True)\n",
    "        \n",
    "    g.close()\n",
    "    h.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEEM_10k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cutoff in cutoffs:\n",
    "        \n",
    "    # Initialize SOAPs and KPCAs\n",
    "    deem_10k = load_structures_from_hdf5('../Processed_Data/DEEM_10k/Data/{cutoff}/soaps.hdf5')\n",
    "    \n",
    "    # Load kernel parameters\n",
    "    with open('../Processed_Data/DEEM_10k/Data/{cutoff}/kernel_parameters.json', 'r') as f:\n",
    "        kernel_dict = json.load(f)\n",
    "    \n",
    "    kernel_type = kernel_dict['kernel_type']\n",
    "    kernel_parameters = kernel_dict['kernel_parameters']\n",
    "    \n",
    "    # Build representative kernel\n",
    "    KMM = build_kernel(representative_soaps['{cutoff}'], representative_soaps['{cutoff}'],\n",
    "                       kernel=kernel_type, **kernel_parameters)\n",
    "    \n",
    "    # Initialize sparse KPCA for environments\n",
    "    iskpca_environments = IterativeSparseKPCA(n_kpca=n_kpca)\n",
    "    iskpca_environments.initialize_fit(KMM)\n",
    "    \n",
    "    # Initialize sparse KPCA for structures\n",
    "    iskpca_structures.IterativeSparseKPCA(n_kpca=n_kpca)\n",
    "    iskpca_structures.initialize_fit(KMM)\n",
    "    \n",
    "    # Fit the sparse KPCA\n",
    "    for soap in deem_10k:\n",
    "        KNMi = build_kernel(soap, representative_soaps['{cutoff}'],\n",
    "                          kernel=kernel_type, **kernel_parameters)\n",
    "        iskpca_environments.fit_batch(KNMi)\n",
    "        iskpca_structures.fit_batch(np.mean(KNMi, axis=0))\n",
    "        \n",
    "    \n",
    "    # Finalize the KPCA fitting\n",
    "    iskpca_environments.finalize_fit()\n",
    "    iskpca_structures.finalize_fit()\n",
    "    \n",
    "    # Pickle the models\n",
    "    # TODO: account for np arrays\n",
    "    with open('../Processed_Data/DEEM_10k/Models/{cutoff}/iskpca_environments.json', 'w') as f:\n",
    "        json.dump(iskpca_environments.__dict__, f)\n",
    "        \n",
    "    with open('../Processed_Data/DEEM_10k/Models/{cutoff}/iskpca_structures.json', 'w') as f:\n",
    "        json.dump(iskpca_structures.__dict__, f)\n",
    "    \n",
    "    # Initialize the KPCA output\n",
    "    g = h5py.File('../Processed_Data/DEEM_10k/Data/{cutoff}/kpca_environments.hdf5', 'w')\n",
    "    h = h5py.File('../Processed_Data/DEEM_10k/Data/{cutoff}/kpca_structures.hdf5', 'w')\n",
    "    \n",
    "    # Save kernel parameters to HDF5 files\n",
    "    for file_obj in (g, h):\n",
    "        file_obj.attrs['kernel_type'] = kernel_type\n",
    "        file_obj.attrs['n_components'] = n_kpca\n",
    "        for key, value in kernel_parameters.items():\n",
    "            file_obj.attrs[key] = value\n",
    "    \n",
    "    # Transform the data and save\n",
    "    for sdx, soap in enumerate(deem_10k):\n",
    "        KNMi = build_kernel(soap, representative_soaps['{cutoff}'],\n",
    "                          kernel=kernel_type, **kernel_parameters)\n",
    "        kpcai_environments = iskpca_environments.transform(KNMi)\n",
    "        kpcai_structures = iskpca_structures.transform(np.mean(KNMi, axis=0))\n",
    "        g.create_dataset('{:d}'.format(sdx), data=kpcai_environments, track_order=True)\n",
    "        h.create_dataset('{:d}'.format(sdx), data=kpcai_structures, track_order=True)\n",
    "        \n",
    "    g.close()\n",
    "    h.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IZA_226 on DEEM_10k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cutoff in cutoffs:\n",
    "    work_dir = '../Processed_Data/IZA_226onDEEM_10k/Data/{cutoff}'\n",
    "    \n",
    "    transform_iskpca(iskpca_environments_file, iskpca_structures_file, kernel_file, \n",
    "                     representative_soaps['{cutoff}'], work_dir=work_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COD_196 on DEEM_10k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
