{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/home/helfrech/Tools/Toolbox/utils')\n",
    "\n",
    "# Maths\n",
    "import numpy as np\n",
    "\n",
    "# ML\n",
    "from decomposition import IterativeSparseKPCA, KPCA\n",
    "from kernels import build_kernel, linear_kernel, gaussian_kernel\n",
    "\n",
    "# Utilities\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: load cutoffs, kernel type, gaussian widths, regularizations, and sigmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: load representative indices and build representative environments for each cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: put reusable code into functions in within this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: pickle the deem kpca models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: functions for DEEM, IZA/COD, IZAonDEEM/CODonDEEM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEEM_10k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cutoff in cutoffs:\n",
    "        \n",
    "    # Initialize SOAPs and KPCAs\n",
    "    deem_10k = []\n",
    "    \n",
    "    # Read SOAPs from HDF5\n",
    "    f = h5py.File('../Processed_Data/DEEM_10k/KPCA/{cutoff}/soaps.hdf5', 'r')\n",
    "    for soap in f.values():\n",
    "        deem_10k.append(soap)\n",
    "    f.close()\n",
    "            \n",
    "    # Build representative kernel\n",
    "    KMM = build_kernel(representative_soaps, representative_soaps,\n",
    "                       kernel=kernel_type, **kernel_parameters)\n",
    "    \n",
    "    # Initialize sparse KPCA for environments\n",
    "    iskpca_environments = IterativeSparseKPCA(n_kpca=n_kpca)\n",
    "    iskpca_environments.initialize_fit(KMM)\n",
    "    \n",
    "    # Initialize sparse KPCA for structures\n",
    "    iskpca_structures.IterativeSparseKPCA(n_kpca=n_kpca)\n",
    "    iskpca_structures.initialize_fit(KMM)\n",
    "    \n",
    "    # Fit the sparse KPCA\n",
    "    for soap in deem_10k:\n",
    "        KNMi = build_kernel(soap, representative_soaps,\n",
    "                          kernel=kernel_type, **kernel_parameters)\n",
    "        iskpca_environments.fit_batch(KNMi)\n",
    "        iskpca_structures.fit_batch(np.mean(KNMi, axis=0))\n",
    "        \n",
    "    \n",
    "    # Finalize the KPCA fitting\n",
    "    iskpca_environments.finalize_fit()\n",
    "    iskpca_structures.finalize_fit()\n",
    "    \n",
    "    # Initialize the KPCA output\n",
    "    g = h5py.File('../Processed_Data/DEEM_10k/KPCA/{cutoff}/kpca_environments.hdf5', 'w')\n",
    "    h = h5py.File('../Processed_Data/DEEM_10k/KPCA/{cutoff}/kpca_structures.hdf5', 'w')\n",
    "    \n",
    "    # TODO: save all the metadata to the files (number of components, kernel params, etc.)\n",
    "    \n",
    "    # Transform the data and save\n",
    "    for sdx, soap in enumerate(deem_10k):\n",
    "        KNMi = build_kernel(soap, representative_soaps,\n",
    "                          kernel=kernel_type, **kernel_params)\n",
    "        kpcai_environments = iskpca_environments.transform(KNMi)\n",
    "        kpcai_structures = iskpca_structures.transform(np.mean(KNMi, axis=0))\n",
    "        g.create_dataset('{:d}'.format(sdx), data=kpcai_environments, track_order=True)\n",
    "        h.create_dataset('{:d}'.format(sdx), data=kpcai_structures, track_order=True)\n",
    "        \n",
    "    g.close()\n",
    "    h.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IZA_226"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pure IZA_226"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for cutoff in cutoffs:\n",
    "        \n",
    "    # Initialize SOAPs and KPCAs\n",
    "    iza_226_structures = []\n",
    "    \n",
    "    # Read SOAPs from HDF5\n",
    "    f = h5py.File('../Processed_Data/IZA_226/KPCA/{cutoff}/soaps.hdf5', 'r')\n",
    "    for soap in f.values():\n",
    "        iza_226_structures.append(soap)\n",
    "    f.close()\n",
    "    \n",
    "    iza_226_environments = np.concatenate(iza_226)\n",
    "    \n",
    "    # Initialize the KPCA\n",
    "    skpca_environments = SparseKPCA(n_kpca=n_kpca)\n",
    "    skpca_structures = SparseKPCA(n_kpca=n_kpca)\n",
    "    \n",
    "    # Build kernel\n",
    "    KMM = build_kernel(representative_soaps_iza, representative_soaps_iza,\n",
    "                       kernel=kernel_type, **kernel_parameters)\n",
    "    KNM_environments = build_kernel(iza_226_environments, representative_soaps_iza,\n",
    "                                    kernel=kernel_type, **kernel_parameters)\n",
    "    KNM_structures = build_kernel(iza_226_structures, representative_soaps_iza,\n",
    "                                  kernel=kernel_type, **kernel_parameters)\n",
    "    \n",
    "    # Fit the KPCA\n",
    "    skpca_environments.fit(KNM_environments, KMM)\n",
    "    skpca_structures.fit(KNM_structures, KMM)\n",
    "            \n",
    "    # Initialize the KPCA output\n",
    "    g = h5py.File('../Processed_Data/IZA_226/KPCA/{cutoff}/kpca_environments.hdf5', 'w')\n",
    "    h = h5py.File('../Processed_Data/IZA_226/KPCA/{cutoff}/kpca_structures.hdf5', 'w')\n",
    "\n",
    "    # TODO: save all the metadata to the file (number of components, kernel params, etc.)\n",
    "    \n",
    "    # Transform the data and save\n",
    "    for sdx, soap in enumerate(iza_226):\n",
    "        KNMi = build_kernel(soap, representative_soaps_iza,\n",
    "                            kernel=kernel_type, **kernel_params)\n",
    "        kpcai_environments = skpca_environments.transform(KNMi)\n",
    "        kpcai_structures = skpca_structures.transform(np.mean(KNMi, axis=0))\n",
    "        g.create_dataset('{:d}'.format(sdx), data=kpcai_environments, track_order=True)\n",
    "        h.create_dataset('{:d}'.format(sdx), data=kpcai_structures, track_order=True)\n",
    "        \n",
    "    g.close()\n",
    "    h.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IZA_226 on DEEM_10k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cutoff in cutoffs:\n",
    "        \n",
    "    # Initialize SOAPs and KPCAs\n",
    "    iza_226 = []\n",
    "    \n",
    "    # Read SOAPs from HDF5\n",
    "    f = h5py.File('../Processed_Data/IZA_226onDEEM_10k/KPCA/{cutoff}/soaps.hdf5', 'r')\n",
    "    for soap in f.values():\n",
    "        iza_226.append(soap)\n",
    "    f.close()\n",
    "    \n",
    "    # Initialize the KPCA output\n",
    "    g = h5py.File('../Processed_Data/IZA_226onDEEM_10k/KPCA/{cutoff}/kpca_environments.hdf5', 'w')\n",
    "    h = h5py.File('../Processed_Data/IZA_226onDEEM_10k/KPCA/{cutoff}/kpca_structures.hdf5', 'w')\n",
    "    \n",
    "    # TODO: save all the metadata to the file (number of components, kernel params, etc.)\n",
    "    \n",
    "    # TODO: transform at once and save iteratively\n",
    "    \n",
    "    # Transform the data and save\n",
    "    for sdx, soap in enumerate(iza_226):\n",
    "        KNMi = build_kernel(soap, representative_soaps,\n",
    "                          kernel=kernel_type, **kernel_params)\n",
    "        kpcai_environments = iskpca_environments.transform(KNMi)\n",
    "        kpcai_structures = iskpca_structures.transform(np.mean(KNMi, axis=0))\n",
    "        g.create_dataset('{:d}'.format(sdx), data=kpcai_environments, track_order=True)\n",
    "        h.create_dataset('{:d}'.format(sdx), data=kpcai_structures, track_order=True)\n",
    "        \n",
    "    g.close()\n",
    "    h.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COD_196"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pure COD_196"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COD_196 on DEEM_10k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
