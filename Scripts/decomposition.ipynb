{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/home/helfrech/Tools/Toolbox/utils')\n",
    "\n",
    "# Maths\n",
    "import numpy as np\n",
    "\n",
    "# ML\n",
    "from decomposition import IterativeSparseKPCA, KPCA\n",
    "from kernels import build_kernel, linear_kernel, gaussian_kernel\n",
    "\n",
    "# Utilities\n",
    "import h5py\n",
    "import json\n",
    "from project_utils import load_structures_from_hdf5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: load cutoffs, kernel type, gaussian widths, regularizations, and sigmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoffs = (3.5, 6.0)\n",
    "representative_soaps = {}\n",
    "\n",
    "for cutoff in cutoffs:\n",
    "    work_dir = '../Processed_Data/DEEM_10k/Data/{cutoff}'\n",
    "    n_Si = np.loadtxt('{work_dir}/n_Si.dat', dtype=int)\n",
    "    split_idxs = np.cumsum(n_Si)[0:-1]\n",
    "    representative_idxs = np.loadtxt('{work_dir}/FPS_representatives.idxs', dtype=int)\n",
    "    soaps_file = '{work_dir}/soaps.hdf5'\n",
    "    representative_soaps['{cutoff}'] = build_representatives_from_hdf5(soaps_file, representative_idxs, split_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: put reusable code into functions in within this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_iskpca(iskpca_environments, iskpca_structures, representative_soaps, \n",
    "                     kernel_type, kernel_params, work_dir='.')\n",
    "    \n",
    "    # Read SOAPs\n",
    "    soaps = load_structures_from_hdf5('{work_dir}/soaps.hdf5')\n",
    "\n",
    "    # Initialize the KPCA output\n",
    "    g = h5py.File('{work_dir}/kpca_environments.hdf5', 'w')\n",
    "    h = h5py.File('{work_dir}/kpca_structures.hdf5', 'w')\n",
    "    \n",
    "    # TODO: save all the metadata to the file (number of components, kernel params, etc.)\n",
    "        \n",
    "    # Transform the data and save\n",
    "    for sdx, soap in enumerate(soaps):\n",
    "        KNMi = build_kernel(soap, representative_soaps,\n",
    "                          kernel=kernel_type, **kernel_parameters)\n",
    "        kpcai_environments = iskpca_environments.transform(KNMi)\n",
    "        kpcai_structures = iskpca_structures.transform(np.mean(KNMi, axis=0))\n",
    "        g.create_dataset('{sdx}'.format(sdx), data=kpcai_environments, track_order=True)\n",
    "        h.create_dataset('{sdx}'.format(sdx), data=kpcai_structures, track_order=True)\n",
    "        \n",
    "    g.close()\n",
    "    h.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEEM_10k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cutoff in cutoffs:\n",
    "        \n",
    "    # Initialize SOAPs and KPCAs\n",
    "    deem_10k = load_structures_from_hdf5('../Processed_Data/DEEM_10k/Data/{cutoff}/soaps.hdf5')\n",
    "\n",
    "    # Build representative kernel\n",
    "    KMM = build_kernel(representative_soaps['{cutoff}'], representative_soaps['{cutoff}'],\n",
    "                       kernel=kernel_type, **kernel_parameters)\n",
    "    \n",
    "    # Initialize sparse KPCA for environments\n",
    "    iskpca_environments = IterativeSparseKPCA(n_kpca=n_kpca)\n",
    "    iskpca_environments.initialize_fit(KMM)\n",
    "    \n",
    "    # Initialize sparse KPCA for structures\n",
    "    iskpca_structures.IterativeSparseKPCA(n_kpca=n_kpca)\n",
    "    iskpca_structures.initialize_fit(KMM)\n",
    "    \n",
    "    # Fit the sparse KPCA\n",
    "    for soap in deem_10k:\n",
    "        KNMi = build_kernel(soap, representative_soaps['{cutoff}'],\n",
    "                          kernel=kernel_type, **kernel_parameters)\n",
    "        iskpca_environments.fit_batch(KNMi)\n",
    "        iskpca_structures.fit_batch(np.mean(KNMi, axis=0))\n",
    "        \n",
    "    \n",
    "    # Finalize the KPCA fitting\n",
    "    iskpca_environments.finalize_fit()\n",
    "    iskpca_structures.finalize_fit()\n",
    "    \n",
    "    # TODO: pickle the models\n",
    "    \n",
    "    # Initialize the KPCA output\n",
    "    g = h5py.File('../Processed_Data/DEEM_10k/Data/{cutoff}/kpca_environments.hdf5', 'w')\n",
    "    h = h5py.File('../Processed_Data/DEEM_10k/Data/{cutoff}/kpca_structures.hdf5', 'w')\n",
    "    \n",
    "    # TODO: save all the metadata to the files (number of components, kernel params, etc.)\n",
    "    \n",
    "    # Transform the data and save\n",
    "    for sdx, soap in enumerate(deem_10k):\n",
    "        KNMi = build_kernel(soap, representative_soaps['{cutoff}'],\n",
    "                          kernel=kernel_type, **kernel_parameters)\n",
    "        kpcai_environments = iskpca_environments.transform(KNMi)\n",
    "        kpcai_structures = iskpca_structures.transform(np.mean(KNMi, axis=0))\n",
    "        g.create_dataset('{:d}'.format(sdx), data=kpcai_environments, track_order=True)\n",
    "        h.create_dataset('{:d}'.format(sdx), data=kpcai_structures, track_order=True)\n",
    "        \n",
    "    g.close()\n",
    "    h.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IZA_226 on DEEM_10k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cutoff in cutoffs:\n",
    "    work_dir = '../Processed_Data/IZA_226onDEEM_10k/Data/{cutoff}'\n",
    "    # TODO: unpickle the models\n",
    "    iskpca_environments = None\n",
    "    iskpca_structures = None\n",
    "    transform_iskpca(iskpca_environments, iskpca_structures, representative_soaps['{cutoff}'], \n",
    "                     kernel_type, kernel_parameters, work_dir=work_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COD_196 on DEEM_10k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
