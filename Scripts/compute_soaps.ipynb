{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/home/helfrech/Tools/Toolbox/utils')\n",
    "\n",
    "# Maths\n",
    "import numpy as np\n",
    "\n",
    "# Atoms\n",
    "from ase.io import read\n",
    "\n",
    "# Utilities\n",
    "import h5py\n",
    "import json\n",
    "from selection import FPS, random_selection\n",
    "from project_utils import load_structures_from_hdf5, build_representatives_from_hdf5\n",
    "\n",
    "# SOAP\n",
    "from soap import quippy_soap, librascal_soap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create root directories\n",
    "if not os.path.exists('../Processed_Data'):\n",
    "    os.mkdir('../Processed_Data')\n",
    "\n",
    "if not os.path.exists('../Results'):\n",
    "    os.mkdir('../Results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup SOAP parameters\n",
    "soap_hyperparameters = dict(max_radial=12,\n",
    "                            max_angular=9,\n",
    "                            cutoff_smooth_width=0.3,\n",
    "                            gaussian_sigma_constant=0.3)\n",
    "# SOAP cutoffs (angstrom)\n",
    "cutoffs = (3.5, 6.0)\n",
    "\n",
    "# Save SOAP hyperparameters for quick reference\n",
    "with open('../Processed_Data/soap_hyperparameters.json', 'w') as f:\n",
    "    soap_hyperparameters_copy = soap_hyperparameters.copy()\n",
    "    soap_hyperparameters_copy['interaction_cutoff'] = cutoffs\n",
    "    json.dump(soap_hyperparameters_copy, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of FPS SOAP components to retain \n",
    "n_components = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of randomly selected structure to use to select the SOAP components\n",
    "n_random = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of representative environments\n",
    "n_representative = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fraction of training structures\n",
    "f_train = 0.7750"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_structure_properties(structures, \n",
    "                                 properties=['Energy_per_Si'], \n",
    "                                 property_names=['structure_energies'],\n",
    "                                 work_dir='.'):\n",
    "    \"\"\"\n",
    "        Extracts and saves number of Si, volumes per Si, and other structure properties\n",
    "    \"\"\"\n",
    "    \n",
    "    if not os.path.exists(work_dir):\n",
    "        os.mkdir(work_dir)\n",
    "    \n",
    "    property_dict = dict(n_Si=[], structure_volumes=[])\n",
    "    \n",
    "    for pn in property_names:\n",
    "        property_dict[pn] = []\n",
    "    \n",
    "    for structure in structures:\n",
    "        Z = structure.get_atomic_numbers()\n",
    "        n_Si = np.count_nonzero(Z == 14)\n",
    "        property_dict['n_Si'].append(n_Si)\n",
    "        property_dict['structure_volumes'].append(structure.cell.volume / n_Si)\n",
    "        \n",
    "        for p, pn in zip(properties, property_names):\n",
    "            property_dict[pn].append(structure.info[p])\n",
    "\n",
    "    for key, value in property_dict:\n",
    "        np.savetxt('{work_dir}/{key}.dat', np.asarray(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_soaps_and_select(structures, cutoff, soap_hyperparameters, n_components=0, work_dir='.'):\n",
    "    \"\"\"\n",
    "        Computes SOAP and selects a set of representative components, which are then saved\n",
    "    \"\"\"\n",
    "    \n",
    "    if not os.path.exists(work_dir):\n",
    "        os.mkdir(work_dir)\n",
    "    \n",
    "    soaps = librascal_soap(sample_structures, [14],\n",
    "                                  interaction_cutoff=cutoff,\n",
    "                                  **soap_hyperparameters)\n",
    "\n",
    "    soaps = np.vstack(sample_soaps)\n",
    "\n",
    "    component_idxs, distances = FPS(soaps.T, n=n_components)\n",
    "    np.savetxt('{work_dir}/FPS_components.idxs', \n",
    "               np.stack((component_idxs, distances), axis=1), fmt='%6d\\t%.18e')\n",
    "    \n",
    "    return component_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_representatives_from_hdf5(work_dir, idxs=None, n_representatives=0):\n",
    "        \n",
    "    soaps = load_structures_from_hdf5('{work_dir}/soaps.hdf5', datasets=None, concatenate=True)\n",
    "    \n",
    "    if idxs is not None:\n",
    "        representatives, distances = FPS(soaps[idxs, :], n=n_representatives)   \n",
    "        np.savetxt('{work_dir}/FPS_representatives.idxs', \n",
    "                   np.stack((representatives, distances), axis=1), fmt='%6d\\t%.18e')\n",
    "    \n",
    "    unique, distances = FPS(soaps, n=-1)\n",
    "    np.savetxt('{work_dir}/FPS_unique.idxs',\n",
    "               np.stack((unique, distances), axis=1), fmt='%6d\\t%.18e')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEEM_10k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DEEM 10k\n",
    "deem_10k = read('../Raw_Data/DEEM_10k/DEEM_10000.xyz', index=':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_structure_properties(deem_10k, \n",
    "                             properties=['Energy_per_Si'], \n",
    "                             property_names=['structure_energies'],\n",
    "                             work_dir='../Processed_Data/DEEM_10k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select random structures from which to select SOAP components\n",
    "random_idxs = random_selection(len(deem_10k), n=n_random)\n",
    "random_structures = [deem_10k[i] for i in random_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cutoff in cutoffs:\n",
    "    work_dir = '../Processed_Data/DEEM_10k/Data/{cutoff}'\n",
    "    component_idxs = compute_soap_and_select(deem_10k, \n",
    "                                             cutoff, \n",
    "                                             soap_hyperparameters, \n",
    "                                             n_components=n_components, \n",
    "                                             work_dir=work_dir)\n",
    "    \n",
    "    output_file = librascal_soap(deem_10k, [14],\n",
    "                                 interaction_cutoff=cutoff,\n",
    "                                 **soap_hyperparameters,\n",
    "                                 component_idxs=component_idxs,\n",
    "                                 output='{work_dir}/soaps.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test sets\n",
    "n_train = int(f_train*len(deem_10k))\n",
    "idxs = np.arange(0, len(deem_10k))\n",
    "np.random.shuffle(idxs)\n",
    "train_idxs = idxs[0:n_train]\n",
    "test_idxs = idxs[n_train:]\n",
    "\n",
    "np.savetxt('../Processed_Data/DEEM_10k/train.idxs', train_idxs, fmt='%d')\n",
    "np.savetxt('../Processed_Data/DEEM_10k/test.idxs', test_idxs, fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build representative and unique environments from train set\n",
    "train_idxs = np.loadtxt('../Processed_Data/DEEM_10k/train.idxs', dtype=int)\n",
    "\n",
    "for cutoff in cutoffs:\n",
    "    work_dir = '../Processed_Data/DEEM_10k/Data/{cutoff}'\n",
    "    select_representatives_from_hdf5(work_dir, train_idxs, n_representatives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IZA on DEEM_10k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load IZA structures\n",
    "iza = read('../Raw_Data/GULP/IZA_226/IZA.xyz', index=':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_structure_properties(iza, \n",
    "                             properties=[], \n",
    "                             property_names=[],\n",
    "                             work_dir='../Processed_Data/IZA_226')\n",
    "\n",
    "iza_energies = np.loadtxt('../Raw_Data/GULP/IZA_226/Energies_IZA.dat', usecols=8)\n",
    "np.savetxt('../Processed_Data/IZA_226/structure_energies.dat', iza_energies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cutoff in cutoffs:\n",
    "    work_dir = '../Processed_Data/IZA_226onDEEM_10k/Data/{cutoff}'\n",
    "    idxs_dir = '../Processed_Data/DEEM_10k/Data/{cutoff}'\n",
    "    \n",
    "    # Load DEEM_10k component indices\n",
    "    component_idxs = np.loadtxt('{idxs_dir}/FPS_components.idxs', usecols=0, dtype=int)\n",
    "    \n",
    "    compute_soaps(iza, \n",
    "                  cutoff, \n",
    "                  soap_hyperparameters, \n",
    "                  component_idxs=component_idxs, \n",
    "                  work_dir=work_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cutoff in cutoffs:\n",
    "    work_dir = '../Processed_Data/IZA_226onDEEM_10k/Data/{cutoff}'\n",
    "    select_representatives_from_hdf5(work_dir, idxs=None, n_representatives=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COD on DEEM_10k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load IZA structures\n",
    "cod = read('../Raw_Data/GULP/COD_196/COD.xyz', index=':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_structure_properties(cod, \n",
    "                             properties=[], \n",
    "                             property_names=[],\n",
    "                             work_dir='../Processed_Data/COD_196')\n",
    "\n",
    "cod_energies = np.loadtxt('../Raw_Data/GULP/COD_196/Energies_COD.dat', usecols=8)\n",
    "np.savetxt('../Processed_Data/COD_196/structure_energies.dat', iza_energies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cutoff in cutoffs:\n",
    "    work_dir = '../Processed_Data/COD_196onDEEM_10k/Data/{cutoff}'\n",
    "    idxs_dir = '../Processed_Data/DEEM_10k/Data/{cutoff}'\n",
    "    \n",
    "    # Load DEEM_10k component indices\n",
    "    component_idxs = np.loadtxt('{idxs_dir}/FPS_components.idxs', usecols=0, dtype=int)\n",
    "    \n",
    "    output_file = librascal_soap(cod, [14],\n",
    "                                 interaction_cutoff=cutoff,\n",
    "                                 **soap_hyperparameters,\n",
    "                                 component_idxs=component_idxs,\n",
    "                                 output='{work_dir}/soaps.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cutoff in cutoffs:\n",
    "    work_dir = '../Processed_Data/COD_196onDEEM_10k/Data/{cutoff}'\n",
    "    select_representatives_from_hdf5(work_dir, idxs=None, n_representatives=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEEM_330k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DEEM 10k\n",
    "deem_330k = read('../Raw_Data/DEEM_330k/XYZ/DEEM_331172.xyz', index=':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_structure_properties(deem_330k, \n",
    "                             properties=['Energy_per_Si'], \n",
    "                             property_names=['structure_energies'],\n",
    "                             work_dir='../Processed_Data/DEEM_330k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cutoff in cutoffs:\n",
    "    work_dir = '../Processed_Data/DEEM_330konDEEM_10k/Data/{cutoff}'\n",
    "    idxs_dir = '../Processed_Data/DEEM_10k/Data/{cutoff}'\n",
    "    \n",
    "    # Load DEEM_10k component indices\n",
    "    component_idxs = np.loadtxt('{idxs_dir}/FPS_components.idxs', usecols=0, dtype=int)\n",
    "    \n",
    "    output_file = librascal_soap(deem_330k, [14],\n",
    "                                 interaction_cutoff=cutoff,\n",
    "                                 **soap_hyperparameters,\n",
    "                                 component_idxs=component_idxs,\n",
    "                                 average=True,\n",
    "                                 output='{work_dir}/soaps.hdf5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
