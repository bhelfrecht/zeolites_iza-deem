{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/home/helfrech/Tools/Toolbox/utils')\n",
    "\n",
    "# Maths\n",
    "import numpy as np\n",
    "\n",
    "# Atoms\n",
    "from ase.io import read\n",
    "\n",
    "# Utilities\n",
    "import project_utils as utils\n",
    "\n",
    "# SOAP\n",
    "from soap import librascal_soap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create root directories\n",
    "if not os.path.exists('../Processed_Data'):\n",
    "    os.mkdir('../Processed_Data')\n",
    "\n",
    "if not os.path.exists('../Results'):\n",
    "    os.mkdir('../Results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOAP cutoffs (angstrom)\n",
    "cutoffs = (3.5, 6.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup SOAP parameters\n",
    "# TODO: define and save the whole set of parameters\n",
    "soap_hyperparameters = dict(max_radial=12,\n",
    "                            max_angular=9,\n",
    "                            cutoff_smooth_width=0.3,\n",
    "                            gaussian_sigma_constant=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save SOAP hyperparameters for quick reference\n",
    "with open('../Processed_Data/soap_hyperparameters.json', 'w') as f:\n",
    "    soap_hyperparameters_copy = soap_hyperparameters.copy()\n",
    "    soap_hyperparameters_copy['interaction_cutoff'] = cutoffs\n",
    "    json.dump(soap_hyperparameters_copy, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_volumes_and_numbers(structures, work_dir='.'):\n",
    "    \"\"\"\n",
    "        Extracts and saves number of Si and volumes per Si\n",
    "    \"\"\"\n",
    "    \n",
    "    # Make required directories\n",
    "    if not os.path.exists(work_dir):\n",
    "        os.makedirs(work_dir)\n",
    "        \n",
    "    n_Si = np.zeros(len(structures), dtype=int)\n",
    "    volumes = np.zeros(len(strucutres))\n",
    "    \n",
    "    # Iterate over structures and fill the property dictionary\n",
    "    for sdx, structure in enumerate(structures):\n",
    "        Z = structure.get_atomic_numbers()\n",
    "        n_Si[sdx] = np.count_nonzero(Z == 14)\n",
    "        volumes[sdx] = structure.cell.volume / n_Si\n",
    "        \n",
    "    np.savetxt(f'{work_dir}/n_Si.dat', fmt='%d')\n",
    "    np.savetxt(f'{work_dir}/structure_volumes.dat', fmt='%.18e')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEEM 330k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_shape = dict(\n",
    "    power=(100, soap_hyperparameters['max_radial']**2 * (soap_hyperparameters['max_angular'] + 1)),\n",
    "    radial=(10000, soap_hyperparameters['max_radial'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DEEM 10k\n",
    "# TODO: rebuild from the CIFs?\n",
    "deem_330k = read('../Raw_Data/DEEM_330k/XYZ/DEEM_331172.xyz', index=':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract volumes and number of Si\n",
    "work_dir = '../Processed_Data/DEEM_330k/Data'\n",
    "extract_volumes_and_numbers(deem_330k, work_dir=work_dir)\n",
    "\n",
    "# Copy over the energies for easy access\n",
    "energies = np.loadtxt('../Raw_Data/GULP/DEEM_330k/optimization_summary_fix.dat', usecols=2)\n",
    "np.savetxt(f'{work_dir}/structure_energies.dat', energies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 331172/331172 [33:33<00:00, 164.44it/s]\n",
      " 96%|█████████▋| 319537/331172 [1:34:30<09:36, 20.20it/s] "
     ]
    }
   ],
   "source": [
    "# Compute unnormalized SOAPs for all structures retaining ALL components, but average over structures\n",
    "for cutoff in cutoffs:\n",
    "    for spectrum, spectrum_label in zip(('PowerSpectrum', 'RadialSpectrum'), ('power', 'radial')):\n",
    "        work_dir = f'../Processed_Data/DEEM_330k/Data/{cutoff}'\n",
    "\n",
    "        # Make required directories\n",
    "        if not os.path.exists(work_dir):\n",
    "            os.makedirs(work_dir)\n",
    "\n",
    "        output_file = librascal_soap(\n",
    "            deem_330k, [14],\n",
    "            interaction_cutoff=cutoff,\n",
    "            soap_type=spectrum,\n",
    "            **soap_hyperparameters,\n",
    "            normalize=False,\n",
    "            component_idxs=None,\n",
    "            average=True,\n",
    "            concatenate=True, # for faster access in processing\n",
    "            chunks=chunk_shape[spectrum_label],\n",
    "            output=f'{work_dir}/soaps_{spectrum_label}_full_avg_nonorm.hdf5'\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract DEEM 10k SOAPs from DEEM 330k SOAPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DEEM 10k\n",
    "deem_10k = read('../Raw_Data/DEEM_10k/DEEM_10000.xyz', index=':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stride construction from the 330k set to get the 10k set\n",
    "deem_10k_idxs = np.arange(0, len(deem_330k), 32)[0:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Check to make sure we have the correct structures\n",
    "print(deem_10k == [deem_330k[i] for i in deem_10k_idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the indices\n",
    "np.savetxt('../Processed_Data/DEEM_330k/deem_10k.idxs', deem_10k_idxs, fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute unnormalized SOAPs for all structures retaining ALL components, but average over structures\n",
    "for cutoff in cutoffs:\n",
    "    for spectrum, spectrum_label in zip(('PowerSpectrum', 'RadialSpectrum'), ('power', 'radial')):\n",
    "        work_dir = f'../Processed_Data/DEEM_10k/Data/{cutoff}'\n",
    "\n",
    "        # Make required directories\n",
    "        if not os.path.exists(work_dir):\n",
    "            os.makedirs(work_dir)\n",
    "\n",
    "        output_file = librascal_soap(\n",
    "            deem_10k, [14],\n",
    "            interaction_cutoff=cutoff,\n",
    "            soap_type=spectrum,\n",
    "            **soap_hyperparameters,\n",
    "            normalize=False,\n",
    "            component_idxs=None,\n",
    "            average=True,\n",
    "            concatenate=False, # Need to be able to access the environments\n",
    "            chunks=chunk_shape[spectrum_label],\n",
    "            output=f'{work_dir}/soaps_{spectrum_label}_full_nonorm.hdf5'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Check that we can pull the correct SOAPs with the indices\n",
    "for cutoff in cutoffs:\n",
    "    for spectrum_label in ('power', 'radial'):\n",
    "        soaps_10k = load_hdf5(\n",
    "            f'../Processed_Data/DEEM_10k/Data/{cutoff}/soaps_{spectrum_label}_full_nonorm.hdf5',\n",
    "            datasets=None, concatenate=False\n",
    "        )\n",
    "        soaps_10k = np.vstack([np.mean(soaps, axis=0) for soaps in soaps_10k])\n",
    "\n",
    "        soaps_330k = load_hdf5(\n",
    "            f'../Processed_Data/DEEM_330k/Data/{cutoff}/soaps_{spectrum_label}_full_avg_nonorm.hdf5',\n",
    "            indices=deem_10k_idxs\n",
    "        )\n",
    "\n",
    "        print(np.allclose(soaps_10k, soaps_330k, rtol=1.0E-12, atol=1.0E-12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IZA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iza_226 = read('../Raw_Data/GULP/IZA_226/IZA_226.xyz', index=':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract volumes and number of Si\n",
    "work_dir = '../Processed_Data/IZA_226/Data'\n",
    "extract_volumes_and_numbers(iza_226, work_dir=work_dir)\n",
    "\n",
    "# Copy over the energies for easy access\n",
    "energies = np.loadtxt('../Raw_Data/GULP/IZA_226/optimization_summary_fix.dat', usecols=2)\n",
    "np.savetxt(f'{work_dir}/structure_energies.dat', energies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:01<00:00, 122.86it/s]\n",
      "100%|██████████| 226/226 [00:04<00:00, 45.47it/s]\n"
     ]
    }
   ],
   "source": [
    "# Compute unnormalized SOAPs for all structures retaining ALL components, but average over structures\n",
    "for cutoff in cutoffs:\n",
    "    for spectrum, spectrum_label in zip(('PowerSpectrum', 'RadialSpectrum'), ('power', 'radial')):\n",
    "        work_dir = f'../Processed_Data/IZA_226/Data/{cutoff}'\n",
    "\n",
    "        # Make required directories\n",
    "        if not os.path.exists(work_dir):\n",
    "            os.makedirs(work_dir)\n",
    "\n",
    "        output_file = librascal_soap(\n",
    "            iza_226, [14],\n",
    "            interaction_cutoff=cutoff,\n",
    "            soap_type=spectrum,\n",
    "            **soap_hyperparameters,\n",
    "            normalize=False,\n",
    "            component_idxs=None,\n",
    "            average=True,\n",
    "            concatenate=True, # For easy access\n",
    "            chunks=chunk_shape[spectrum_label],\n",
    "            output=f'{work_dir}/soaps_{spectrum_label}_full_nonorm.hdf5'\n",
    "        ) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
