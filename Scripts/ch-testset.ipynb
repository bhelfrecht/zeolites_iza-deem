{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/home/helfrech/Tools/Toolbox/utils')\n",
    "\n",
    "# Maths\n",
    "import numpy as np\n",
    "from scipy.spatial import Voronoi, ConvexHull\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Atoms\n",
    "from ase.io import read, write\n",
    "\n",
    "# ML\n",
    "from skcosmo.decomposition import PCovR\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Utilities\n",
    "import h5py\n",
    "import json\n",
    "import subprocess\n",
    "import glob\n",
    "from copy import deepcopy\n",
    "import project_utils as utils\n",
    "from tools import save_json, load_json, recursive_array_convert\n",
    "\n",
    "# SOAP\n",
    "from soap import librascal_soap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the hull distances\n",
    "def hull_distances(hull, data):\n",
    "        \n",
    "    # Omit the simplices on the 'top' of the CH\n",
    "    hull_facets = np.delete(\n",
    "        hull.equations,\n",
    "        np.nonzero(hull.equations[:, 0] > 0.0),\n",
    "        axis=0\n",
    "    )\n",
    "    \n",
    "    hull_distance = -1.0 * (\n",
    "        np.matmul(data, hull_facets[:, 0:-1].T) \n",
    "        + hull_facets[:, -1]\n",
    "    )\n",
    "    \n",
    "    hull_distance_energy = -1.0 * hull_distance / hull_facets[:, 0]\n",
    "    \n",
    "    hull_distance = np.amin(hull_distance, axis=1)\n",
    "    hull_distance_energy = np.amin(hull_distance_energy, axis=1)\n",
    "    \n",
    "    return hull_distance, hull_distance_energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 6.0\n",
    "spectrum = 'power'\n",
    "spectrum_name = spectrum.capitalize()\n",
    "n_cantons = 4\n",
    "group_name = 'OO+OSi+SiSi'\n",
    "mixing_suffixes = ['', '_0.0', '_1.0']\n",
    "df_types = ['OvR', 'OvO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = '../Processed_Data/Models'\n",
    "\n",
    "deem_name = 'DEEM_330k'\n",
    "iza_name = 'IZA_230'\n",
    "deem_dir = f'../Processed_Data/{deem_name}/Data'\n",
    "iza_dir = f'../Processed_Data/{iza_name}/Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train sets for IZA and Deem\n",
    "iza_train_idxs = np.loadtxt(f'../Processed_Data/IZA_230/svm_train.idxs', dtype=int)\n",
    "iza_sort_train_idxs = np.argsort(iza_train_idxs)\n",
    "iza_unsort_train_idxs = np.argsort(iza_sort_train_idxs)\n",
    "\n",
    "deem_train_idxs = np.loadtxt('../Processed_Data/DEEM_330k/svm_train.idxs', dtype=int)\n",
    "\n",
    "# Load test sets for IZA and Deem\n",
    "iza_test_idxs = np.loadtxt('../Processed_Data/IZA_230/svm_test.idxs', dtype=int)\n",
    "iza_sort_test_idxs = np.argsort(iza_test_idxs)\n",
    "iza_unsort_test_idxs = np.argsort(iza_sort_test_idxs)\n",
    "\n",
    "deem_test_idxs = np.loadtxt('../Processed_Data/DEEM_330k/svm_test.idxs', dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "iza_frames = read('../Raw_Data/GULP/IZA_230/IZA_230.xyz', index=':')\n",
    "deem_frames = read('../Raw_Data/DEEM_330k/XYZ/DEEM_331172.xyz', index=':')\n",
    "frames = [iza_frames[i] for i in iza_test_idxs] + [deem_frames[i] for i in deem_test_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "deem_energies = np.loadtxt('../Raw_Data/GULP/DEEM_330k/optimization_summary.dat', usecols=(1, 2)) # 1=Ref, 2=GULP\n",
    "iza_energies = np.loadtxt('../Raw_Data/GULP/IZA_230/optimization_summary_fix.dat', usecols=1) # 1=GULP\n",
    "train_energies = np.concatenate((iza_energies[iza_train_idxs], deem_energies[deem_train_idxs, 1]))\n",
    "test_energies = np.concatenate((iza_energies[iza_test_idxs], deem_energies[deem_test_idxs, 1]))\n",
    "\n",
    "# Center energies relative to the train set\n",
    "energy_scaler = utils.StandardNormScaler(with_mean=True, with_scale=False)\n",
    "train_energies = energy_scaler.fit_transform(train_energies)\n",
    "test_energies = energy_scaler.transform(test_energies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a convex hull based on PCovR projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    " # CH dimensions (includes energy)\n",
    "ndim = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a standard convex hull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== OvR =====\n",
      "----- CH for PCovR with optimal mixing -----\n",
      "----- CH for PCovR with mixing = 0.0 -----\n",
      "----- CH for PCovR with mixing = 1.0 -----\n",
      "===== OvO =====\n",
      "----- CH for PCovR with optimal mixing -----\n",
      "----- CH for PCovR with mixing = 0.0 -----\n",
      "----- CH for PCovR with mixing = 1.0 -----\n"
     ]
    }
   ],
   "source": [
    "for df_type in df_types:\n",
    "    print(f'===== {df_type} =====')\n",
    "    \n",
    "    ch_dir = f'{model_dir}/{cutoff}/CH_TESTSET/{df_type}/{n_cantons}-Class/{spectrum_name}/{group_name}'\n",
    "    os.makedirs(ch_dir, exist_ok=True)\n",
    "    \n",
    "    model_data_dir = f'LPCovR/{df_type}/{n_cantons}-Class/{spectrum_name}/{group_name}'\n",
    "\n",
    "    # Save frames and energies in duplicate\n",
    "    # for compatibility with the (deprecated) GCH framework\n",
    "    write(f'{ch_dir}/iza+deem.xyz', frames, format='extxyz')\n",
    "    np.savetxt(f'{ch_dir}/energies_per_si.dat', test_energies)\n",
    "    \n",
    "    for mixing in mixing_suffixes:\n",
    "        if mixing == '':\n",
    "            print('----- CH for PCovR with optimal mixing -----')\n",
    "        else:\n",
    "            print(f'----- CH for PCovR with mixing = {mixing[1:]} -----')\n",
    "                \n",
    "        T = np.concatenate((\n",
    "            utils.load_hdf5(\n",
    "                f'{iza_dir}/{cutoff}/{model_data_dir}/pcovr_structure_projections{mixing}.hdf5',\n",
    "                indices=iza_test_idxs[iza_sort_test_idxs]\n",
    "            )[iza_unsort_test_idxs],\n",
    "            utils.load_hdf5(\n",
    "                f'{deem_dir}/{cutoff}/{model_data_dir}/pcovr_structure_projections{mixing}.hdf5',\n",
    "                indices=deem_test_idxs\n",
    "            )\n",
    "        ))\n",
    "\n",
    "        # Load projections\n",
    "        data = np.column_stack((test_energies, T[:, 0:ndim-1]))\n",
    "        ch = ConvexHull(data)\n",
    "\n",
    "        d, de = hull_distances(ch, data)\n",
    "        \n",
    "        # Save projections and distances.\n",
    "        # Projections are saved in duplicate\n",
    "        # for compatibility with the (deprecated) GCH framework\n",
    "        np.savetxt(f'{ch_dir}/T{mixing}.dat', T)\n",
    "        np.savetxt(f'{ch_dir}/hull_distances{mixing}.dat', d)\n",
    "        np.savetxt(f'{ch_dir}/hull_distances_energy{mixing}.dat', de)\n",
    "        np.savetxt(f'{ch_dir}/hull_vertices{mixing}.dat', ch.vertices, fmt='%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voronoi tesselation"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Load SOAPs\n",
    "deem_soaps = utils.load_hdf5(f'{deem_dir}/{cutoff}/soaps_{spectrum}/full_avg_nonorm.hdf5')\n",
    "iza_soaps = utils.load_hdf5(f'{iza_dir}/{cutoff}/soaps_{spectrum}/full_avg_nonorm.hdf5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
